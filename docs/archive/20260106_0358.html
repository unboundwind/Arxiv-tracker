<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-06 03:58</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260106_0358</div>
    <div class="row"><div class="card">
<div class="title">AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction</div>
<div class="meta-line">Authors: Jiewen Chan, Zhenjun Zhao, Yu-Lun Liu</div>
<div class="meta-line">First: 2026-01-02T18:59:55+00:00 · Latest: 2026-01-02T18:59:55+00:00</div>
<div class="meta-line">Comments: Project page: https://jiewenchan.github.io/AdaGaR/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00796v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00796v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://jiewenchan.github.io/AdaGaR/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AdaGaR：用于动态场景重建的自适应Gabor表示</div>
<div class="mono" style="margin-top:8px">从单目视频中重建动态3D场景需要同时捕捉高频外观细节和时间连续的运动。现有方法使用单高斯基元存在低通滤波的局限性，而标准Gabor函数则引入能量不稳定问题。此外，缺乏时间连续性约束通常会导致插值过程中出现运动伪影。我们提出AdaGaR，一个统一框架，用于显式动态场景建模中的频率自适应性和时间连续性。我们引入自适应Gabor表示，通过可学习的频率权重和自适应能量补偿扩展高斯基元，以在细节捕捉和稳定性之间取得平衡。为实现时间连续性，我们采用带时间曲率正则化的三次Hermite样条，确保运动的平滑演化。一个结合深度估计、点跟踪和前景掩码的自适应初始化机制，在早期训练中建立了稳定的点云分布。在Tap-Vid DAVIS数据集上的实验表明，AdaGaR在帧插值、深度一致性、视频编辑和立体视图合成方面表现出最先进的性能（PSNR 35.49，SSIM 0.9433，LPIPS 0.0723）。</div>
</details>
</div>
<div class="card">
<div class="title">Effects of Structural Allocation of Geometric Task Diversity in Linear Meta-Learning Models</div>
<div class="meta-line">Authors: Saptati Datta, Nicolas W. Hengartner, Yulia Pimonova, Natalie E. Klein, Nicholas Lubbers</div>
<div class="meta-line">First: 2025-09-22T19:16:59+00:00 · Latest: 2026-01-02T18:59:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18349v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.18349v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Meta-learning aims to leverage information across related tasks to improve prediction on unlabeled data for new tasks when only a small number of labeled observations are available (&quot;few-shot&quot; learning). Increased task diversity is often believed to enhance meta-learning by providing richer information across tasks. However, recent work by Kumar et al. (2022) shows that increasing task diversity, quantified through the overall geometric spread of task representations, can in fact degrade meta-learning prediction performance across a range of models and datasets. In this work, we build on this observation by showing that meta-learning performance is affected not only by the overall geometric variability of task parameters, but also by how this variability is allocated relative to an underlying low-dimensional structure. Similar to Pimonova et al. (2025), we decompose task-specific regression effects into a structurally informative component and an orthogonal, non-informative component. We show theoretically and through simulation that meta-learning prediction degrades when a larger fraction of between-task variability lies in orthogonal, non-informative directions, even when the overall geometric variability of tasks is held fixed.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>线性元学习模型中几何任务多样性结构分配的影响</div>
<div class="mono" style="margin-top:8px">元学习旨在利用相关任务之间的信息，以提高在新任务上对未标记数据的预测能力，特别是在仅有少量标记观测数据的情况下（&quot;少样本&quot;学习）。通常认为，增加任务多样性可以提升元学习性能，因为它能提供更丰富的任务间信息。然而，Kumar 等人（2022）的近期研究显示，通过任务表示的整体几何分布来量化任务多样性，实际上可能在多种模型和数据集上降低元学习的预测性能。在本工作中，我们基于这一观察，表明元学习性能不仅受任务参数整体几何变化的影响，还受这种变化如何相对于潜在的低维结构进行分配的影响。类似 Pimonova 等人（2025）的工作，我们将任务特定的回归效应分解为结构信息成分和正交、非信息成分。我们通过理论分析和模拟实验表明，即使任务的整体几何变化保持不变，当任务间变化的更大比例存在于正交、非信息方向时，元学习预测性能会下降。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Meta-learning aims to leverage information across related tasks to improve prediction on unlabeled data for new tasks when only a small number of labeled observations are available (&quot;few-shot&quot; learning).</div>
</details>
</div>
<div class="card">
<div class="title">Distributed Sparse Linear Regression under Communication Constraints</div>
<div class="meta-line">Authors: Rodney Fonseca, Boaz Nadler</div>
<div class="meta-line">First: 2023-01-09T08:23:37+00:00 · Latest: 2026-01-02T18:58:26+00:00</div>
<div class="meta-line">Comments: 50 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2301.04022v2">Abs</a> · <a href="https://arxiv.org/pdf/2301.04022v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In multiple domains, statistical tasks are performed in distributed settings, with data split among several end machines that are connected to a fusion center. In various applications, the end machines have limited bandwidth and power, and thus a tight communication budget. In this work we focus on distributed learning of a sparse linear regression model, under severe communication constraints. We propose several two round distributed schemes, whose communication per machine is sublinear in the data dimension. In our schemes, individual machines compute debiased lasso estimators, but send to the fusion center only very few values. On the theoretical front, we analyze one of these schemes and prove that with high probability it achieves exact support recovery at low signal to noise ratios, where individual machines fail to recover the support. We show in simulations that our scheme works as well as, and in some cases better, than more communication intensive approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在通信约束下的分布式稀疏线性回归</div>
<div class="mono" style="margin-top:8px">在多个领域中，统计任务在分布式环境中进行，数据分布在多个终端设备上，这些设备连接到一个融合中心。在各种应用中，终端设备具有有限的带宽和电源，因此通信预算非常紧张。本文重点研究在严重通信约束下分布式学习稀疏线性回归模型的问题。我们提出了几种两轮分布式方案，其每台设备的通信量与数据维度呈次线性关系。在我们的方案中，每个终端设备计算去偏的Lasso估计量，但仅发送少量值。在理论方面，我们分析了其中一个方案，并证明在低信噪比下，该方案以高概率实现精确的支持恢复，而单个终端设备无法做到。仿真结果表明，我们的方案在效果上与更耗费通信量的方法相当，某些情况下甚至更好。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In multiple domains, statistical tasks are performed in distributed settings, with data split among several end machines that are connected to a fusion center.</div>
</details>
</div>
<div class="card">
<div class="title">Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI</div>
<div class="meta-line">Authors: Wenhui Chu, Nikolaos V. Tsekos</div>
<div class="meta-line">Venue: 2022 12th International Conference on Bioscience, Biochemistry and Bioinformatics (ICBBB &#x27;22), January 7-10, 2022, Tokyo, Japan</div>
<div class="meta-line">First: 2026-01-02T18:56:15+00:00 · Latest: 2026-01-02T18:56:15+00:00</div>
<div class="meta-line">Comments: 7 pages, 5 figures, published in ICBBB 2022</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00794v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00794v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于心肌电影磁共振成像左心室自动分割的两种深度学习方法</div>
<div class="mono" style="margin-top:8px">左心室（LV）分割对于心脏图像的临床量化和诊断至关重要。本文提出两种新的深度学习架构LNU-Net和IBU-Net，用于从短轴电影磁共振成像（cine MRI）图像中进行左心室分割。LNU-Net基于层归一化（LN）U-Net架构，而IBU-Net则基于用于医学图像分割的实例-批次归一化（IB）U-Net架构。LNU-Net和IBU-Net的架构包含用于特征提取的下采样路径和用于精确定位的上采样路径。我们使用原始U-Net作为基础分割方法，并将其与我们提出的架构进行比较。LNU-Net和IBU-Net均包含左心室分割方法：LNU-Net在每个卷积块中应用层归一化，而IBU-Net在第一个卷积块中同时引入实例和批次归一化，并将结果传递给下一层。我们的方法在图像数据处理中引入了仿射变换和弹性形变。我们使用包含45名患者805张左心室MRI图像的数据集进行评估。实验结果表明，所提出的方法在Dice系数和平均垂直距离方面优于其他最先进的方法。</div>
</details>
</div>
<div class="card">
<div class="title">Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning</div>
<div class="meta-line">Authors: Valentin Noël</div>
<div class="meta-line">First: 2026-01-02T18:49:37+00:00 · Latest: 2026-01-02T18:49:37+00:00</div>
<div class="meta-line">Comments: 58 pages, 19 figures, Under Review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00791v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00791v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen&#x27;s $d = 3.30$ ($p &lt; 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B&#x27;s Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>理性几何：有效数学推理的谱特征</div>
<div class="mono" style="margin-top:8px">我们提出了一种无需训练的方法，通过分析注意力模式的谱特性来检测大型语言模型中的有效数学推理。将注意力矩阵视为在标记上动态图的邻接矩阵，我们提取了四个可解释的谱诊断指标：费德勒值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵，这些指标在有效与无效数学证明之间表现出统计上显著的差异。在四个独立架构家族的七种Transformer模型上进行的实验表明，这种谱特征可以产生高达Cohen的$d = 3.30$（$p &lt; 10^{-116}$）的效果量，使得在严格评估下分类准确率达到85.0--95.6\%，在完整数据集上校准后的阈值达到93--95\%。该方法不需要训练数据、微调或学习分类器：只需在谱度量上设置一个单一阈值即可实现高准确率。通过系统性的标签修正，我们发现该谱方法检测的是逻辑一致性，而非编译器接受度，能够识别出形式验证器因技术故障而拒绝的数学上有效的证明。我们进一步发现了一种架构依赖性：Mistral-7B的滑动窗口注意力将判别信号从HFER转移到晚期层的平滑度（$d = 2.09$，$p_{\text{MW}} = 1.16 \times 10^{-48}$），揭示了注意力机制设计对哪些谱特征能够捕捉推理有效性的影响。这些发现确立了谱图分析作为推理验证的原理性框架，并在幻觉检测和人工智能安全监控方面具有直接的应用价值。</div>
</details>
</div>
<div class="card">
<div class="title">Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection</div>
<div class="meta-line">Authors: Shukesh Reddy, Srijan Das, Abhijit Das</div>
<div class="meta-line">First: 2026-01-02T18:47:36+00:00 · Latest: 2026-01-02T18:47:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00789v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00789v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Fusion-SSAT：通过特征融合释放自监督辅助任务在通用深度伪造检测中的潜力</div>
<div class="mono" style="margin-top:8px">在本工作中，我们尝试将自监督学习作为辅助任务，以优化通用深度伪造检测的主要任务。为此，我们考察了不同训练方案的组合，以找到最有效的方案。我们的研究结果表明，融合自监督辅助任务的特征表示是一种强大的特征表示方法。这种表示能够充分利用自监督任务和主要任务的潜力，带来独特的特征表达，从而在主要任务上实现更好的性能。我们在多个大型数据集上进行了实验，包括DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter和UADFV，实验结果表明，与当前最先进的检测器相比，我们的方法在跨数据集评估中表现出更好的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">KAN-Therm: A Lightweight Battery Thermal Model Using Kolmogorov-Arnold Network</div>
<div class="meta-line">Authors: Soumyoraj Mallick, Faysal Ahamed, Sanchita Ghosh, Tanushree Roy</div>
<div class="meta-line">First: 2025-09-11T04:43:09+00:00 · Latest: 2026-01-02T18:47:27+00:00</div>
<div class="meta-line">Comments: 15 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.09145v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.09145v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A battery management system (BMS) relies on real-time estimation of battery temperature distribution in battery cells to ensure safe and optimal operation of Lithium-ion batteries. However, physical BMS often suffers from memory and computational resource limitations required by high-fidelity models. Temperature estimation of batteries for safety-critical systems using physics-based models on physical BMS can potentially become challenging due to their higher computational time. In contrast, neural network based approaches offer faster estimation but require greater memory overhead. To address these challenges, we propose Kolmogorov-Arnold network (KAN) based thermal model, KAN-therm, to estimate the core temperature of a cylindrical battery. Unlike traditional neural network architectures, KAN uses learnable nonlinear activation functions that can effectively capture system complexity using relatively lean models. We have compared the memory overhead and estimation time of our model with state-of-the-art neural network models to demonstrate the applicability and potential scalability of KAN-therm on a physical BMS.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>KAN-Therm：一种基于Kolmogorov-Arnold网络的轻量级电池热模型</div>
<div class="mono" style="margin-top:8px">电池管理系统（BMS）依赖于对电池单体温度分布的实时估计，以确保锂离子电池的安全和最优运行。然而，物理BMS通常受到高保真模型所需内存和计算资源的限制。在安全关键系统中，基于物理模型的电池温度估计可能因计算时间较长而变得具有挑战性。相比之下，基于神经网络的方法虽然估计速度更快，但需要更大的内存开销。为了解决这些挑战，我们提出了一种基于Kolmogorov-Arnold网络（KAN）的热模型KAN-Therm，用于估计圆柱形电池的核心温度。与传统神经网络架构不同，KAN使用可学习的非线性激活函数，能够通过相对简洁的模型有效捕捉系统复杂性。我们通过与最先进的神经网络模型进行比较，展示了KAN-Therm在物理BMS上的适用性和潜在可扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">Callisto&#x27;s Nonresonant Orbit as an Outcome of Circum-Jovian Disk Substructure</div>
<div class="meta-line">Authors: Teng Ee Yap, Konstantin Batygin</div>
<div class="meta-line">Venue: The Astrophysical Journal, 995(2), 218 (2025)</div>
<div class="meta-line">First: 2026-01-02T18:41:18+00:00 · Latest: 2026-01-02T18:41:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00786v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00786v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The Galilean moons of Io, Europa, and Ganymede exhibit a 4:2:1 commensurability in their mean motions, a configuration known as the Laplace resonance. The prevailing view for the origin of this three-body resonance involves the convergent migration of the moons, resulting from gas-driven torques in the circum-Jovian disk wherein they accreted. To account for Callisto&#x27;s exclusion from the resonant chain, a late and/or slow accretion of the fourth and outermost Galilean moon is typically invoked, stalling its migration. Here, we consider an alternative scenario in which Callisto&#x27;s nonresonant orbit is a consequence of disk substructure. Using a suite of N-body simulations that self-consistently account for satellite-disk interactions, we show that a pressure bump can function as a migration trap, isolating Callisto and alleviating constraints on its timing of accretion. Our simulations position the bump interior to the birthplaces of all four moons. In exploring the impact of bump structure on simulation outcomes, we find that it cannot be too sharp nor flat to yield the observed orbital architecture. In particular, a &quot;Goldilocks&quot; zone is mapped in parameter space, corresponding to a well-defined range in bump aspect ratio. Within this range, Io, Europa, and Ganymede are sequentially trapped at the bump, and ushered across it through resonant lockstep migration with their neighboring, exterior moon. The implications of our work are discussed in the context of uncertainties regarding Callisto&#x27;s interior structure, arising from the possibility of non-hydrostatic contributions to its shape and gravity field, unresolved by the Galileo spacecraft.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>卡利斯托的非共振轨道是木星盘子结构的结果</div>
<div class="mono" style="margin-top:8px">木卫一、欧罗巴和甘尼米德这三个伽利略卫星展现出4:2:1的轨道共振，这种配置被称为拉普拉斯共振。目前主流观点认为这种三体共振的起源是由于这些卫星在木星盘中通过气体驱动的扭矩进行收敛迁移。为了解释卡利斯托未参与共振链的情况，通常假定第四颗也是最外层的伽利略卫星在后期或缓慢地形成，从而使其迁移停滞。在此，我们提出了一种替代情景，即卡利斯托的非共振轨道是由于盘中存在子结构所导致。通过一系列自洽考虑卫星与盘相互作用的N体模拟，我们表明压力突增可以作为一个迁移陷阱，将卡利斯托隔离，并减轻其形成时间的约束。我们的模拟显示，该压力突增位于所有四颗卫星的诞生位置内侧。在研究压力突增结构对模拟结果的影响时，我们发现它不能过于尖锐或平坦，否则无法形成观测到的轨道结构。特别地，在参数空间中我们找到了一个“恰到好处”的区域，对应于一个明确的突增纵横比范围。在这个范围内，木卫一、欧罗巴和甘尼米德依次被压力突增捕获，并通过与邻近外侧卫星的共振同步迁移穿过该区域。我们讨论了这项工作的意义，特别是在卡利斯托内部结构方面的不确定性，这些不确定性源于其形状和重力场可能存在的非流体静力贡献，而这些贡献未能被伽利略探测器解析。</div>
</details>
</div>
<div class="card">
<div class="title">FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing</div>
<div class="meta-line">Authors: Sunny Gupta, Amit Sethi</div>
<div class="meta-line">First: 2026-01-02T18:40:41+00:00 · Latest: 2026-01-02T18:40:41+00:00</div>
<div class="meta-line">Comments: 10 pages, 1 figures, Accepted at AAI&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00785v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00785v1">PDF</a> · <a href="http://github.com/sunnyinAI/FedHypeVAE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FedHypeVAE: 基于超网络生成条件VAE的联邦学习用于差分隐私嵌入共享</div>
<div class="mono" style="margin-top:8px">联邦数据共享承诺在不集中原始数据的情况下提供实用性，但现有的嵌入级生成器在非独立同分布（non-IID）客户端异质性下表现不佳，并且对梯度泄露的正式保护有限。我们提出FedHypeVAE，这是一个差分隐私驱动的框架，用于在去中心化的客户端之间合成嵌入级数据。基于条件VAE架构，我们用由共享超网络生成的客户端感知解码器和类别条件先验替代单一全局解码器和固定潜在先验。这种双层设计在生成层实现个性化，而非下游模型，同时将本地数据与通信参数解耦。共享超网络在差分隐私下进行优化，确保仅聚合噪声扰动和裁剪后的梯度。在本地通过真实与合成嵌入之间的MMD对齐以及对超网络输出的Lipschitz正则化，进一步增强了在非IID条件下的稳定性与分布一致性。训练完成后，一个中立的元代码可实现领域无关的合成，而元代码的混合则提供了可控的多领域覆盖。FedHypeVAE在生成层统一了个性化、隐私保护和分布对齐，为联邦环境下的隐私保护数据合成建立了原理性基础。代码：github.com/sunnyinAI/FedHypeVAE</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage.</div>
</details>
</div>
<div class="card">
<div class="title">Categorical Reparameterization with Denoising Diffusion models</div>
<div class="meta-line">Authors: Samson Gourevitch, Alain Durmus, Eric Moulines, Jimmy Olsson, Yazid Janati</div>
<div class="meta-line">First: 2026-01-02T18:30:05+00:00 · Latest: 2026-01-02T18:30:05+00:00</div>
<div class="meta-line">Comments: working paper</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00781v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00781v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于去噪扩散模型的分类变量重参数化</div>
<div class="mono" style="margin-top:8px">基于梯度的分类变量优化通常依赖于无偏但噪声较大的得分函数估计器，或者依赖于连续松弛方法，通过将离散分布替换为可计算路径梯度的平滑替代分布来优化，但代价是使用一个有偏且依赖温度的优化目标。在本文中，我们通过引入基于扩散的软重参数化方法扩展了这一类松弛方法。对于这些分布，基于高斯噪声过程的去噪器具有闭合形式且可高效计算，从而实现无需训练的扩散采样器，并支持反向传播。我们的实验表明，所提出的重参数化技巧在各种基准测试中能够实现竞争性或更优的优化性能。</div>
</details>
</div>
<div class="card">
<div class="title">Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients</div>
<div class="meta-line">Authors: Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa</div>
<div class="meta-line">First: 2025-12-28T21:57:42+00:00 · Latest: 2026-01-02T18:25:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.23090v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.23090v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) using only 2,000 SFT samples, 1,000 RL samples, and a single A100 GPU. Evaluations on CheXpert and NIH benchmarks reveal a fundamental tension: GRPO recovers in-distribution performance (23% improvement on CheXpert, macro-F1 = 0.346) but degrades cross-dataset transferability (19% drop on NIH). This mirrors high-resource models like NV-Reason-CXR-3B, suggesting the issue stems from the RL paradigm rather than scale. We identify a generalization paradox where the SFT checkpoint uniquely improves on NIH before optimization, indicating teacher-guided reasoning captures more institution-agnostic features. Furthermore, cross-model comparisons show structured reasoning scaffolds benefit general-purpose VLMs but offer minimal gain for medically pre-trained models. Consequently, curated supervised fine-tuning may outperform aggressive RL for clinical deployment requiring robustness across diverse populations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基准成功，临床失败：当强化学习优化基准而非患者时</div>
<div class="mono" style="margin-top:8px">近期针对大型语言模型（LLMs）的强化学习（RL）进展提升了推理任务的表现，但其在医疗影像中的资源受限应用仍缺乏探索。我们引入了ChexReason，这是一个通过R1式方法（SFT后接GRPO）训练的视觉-语言模型，仅使用2,000个SFT样本、1,000个RL样本和一个A100 GPU。在CheXpert和NIH基准上的评估揭示了一个根本性矛盾：GRPO在分布内性能上有所恢复（在CheXpert上提升23%，macro-F1 = 0.346），但跨数据集迁移能力下降（在NIH上下降19%）。这与高资源模型如NV-Reason-CXR-3B的表现相似，表明问题源于强化学习范式而非模型规模。我们发现了一个泛化悖论，即SFT检查点在优化前对NIH表现有独特提升，表明教师引导的推理捕捉了更多机构无关的特征。此外，跨模型比较显示，结构化推理框架对通用VLM有益，但对医学预训练模型收益有限。因此，精心策划的监督微调可能在需要跨多样化人群保持稳健性的临床部署中优于激进的强化学习。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored.</div>
</details>
</div>
<div class="card">
<div class="title">Semantic Anchor Transport: Robust Test-Time Adaptation for Vision-Language Models</div>
<div class="meta-line">Authors: Shambhavi Mishra, Julio Silva-Rodriguez, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz</div>
<div class="meta-line">First: 2024-11-26T00:15:37+00:00 · Latest: 2026-01-02T18:18:27+00:00</div>
<div class="meta-line">Comments: Added additional figures to communicate the algorithm</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.17002v3">Abs</a> · <a href="https://arxiv.org/pdf/2411.17002v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large pre-trained vision-language models (VLMs), such as CLIP, have shown unprecedented zero-shot performance across a wide range of tasks. Nevertheless, these models may be unreliable under distributional shifts, as their performance is significantly degraded. In this work, we investigate how to efficiently utilize class text information to mitigate distribution drifts encountered by VLMs during inference. In particular, we propose generating pseudo-labels for the noisy test-time samples by aligning visual embeddings with reliable, text-based semantic anchors. Specifically, to maintain the regular structure of the dataset properly, we formulate the problem as a batch-wise label assignment, which is efficiently solved using Optimal Transport. Our method, Semantic Anchor Transport (SAT), utilizes such pseudo-labels as supervisory signals for test-time adaptation, yielding a principled cross-modal alignment solution. Moreover, SAT further leverages heterogeneous textual clues, with a multi-template distillation approach that replicates multi-view contrastive learning strategies in unsupervised representation learning without incurring additional computational complexity. Extensive experiments on multiple popular test-time adaptation benchmarks presenting diverse complexity empirically show the superiority of SAT, achieving consistent performance gains over recent state-of-the-art methods, yet being computationally efficient.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语义锚点传输：视觉-语言模型的鲁棒推理时适应</div>
<div class="mono" style="margin-top:8px">大型预训练视觉-语言模型（VLMs），如CLIP，在各种任务中表现出前所未有的零样本性能。然而，这些模型在分布变化下可能不可靠，因为其性能会显著下降。本文研究如何高效利用类别文本信息来缓解VLMs在推理过程中遇到的分布漂移问题。具体而言，我们提出通过将视觉嵌入与可靠的文本语义锚点对齐，为噪声测试样本生成伪标签。为了保持数据集的常规结构，我们将问题建模为批量标签分配，并利用最优传输高效求解。我们的方法Semantic Anchor Transport（SAT）利用这些伪标签作为推理时适应的监督信号，提供了一种原理性的跨模态对齐方案。此外，SAT进一步利用异构文本线索，采用多模板蒸馏方法，在无监督表征学习中复制多视角对比学习策略，而不会增加额外的计算复杂度。在多个流行的推理时适应基准上进行的大量实验表明，SAT在不同复杂度的任务中均表现出优越性，相较于近期最先进的方法实现了稳定性能提升，同时保持计算效率。</div>
</details>
</div>
<div class="card">
<div class="title">Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection</div>
<div class="meta-line">Authors: Akanksha Chuchra, Shukesh Reddy, Sudeepta Mishra, Abhijit Das, Abhinav Dhall</div>
<div class="meta-line">First: 2026-01-02T18:17:22+00:00 · Latest: 2026-01-02T18:17:22+00:00</div>
<div class="meta-line">Comments: Accepted at IJCB 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00777v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00777v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在音频深度伪造检测背景下探究多模态大语言模型的应用可行性</div>
<div class="mono" style="margin-top:8px">尽管视觉-语言模型（VLMs）和多模态大语言模型（MLLMs）在检测图像和视频深度伪造方面表现出强大的泛化能力，但它们在音频深度伪造检测中的应用仍鲜有探索。本研究旨在探讨MLLMs在音频深度伪造检测中的潜力。我们通过将音频输入与多种文本提示结合，作为查询来评估MLLMs在跨模态学习稳健表示方面的可行性。因此，我们尝试探索基于文本感知和上下文丰富的问答式提示，并进行二元决策。我们假设这种特征引导的推理有助于促进更深层次的多模态理解，并实现音频深度伪造检测中的稳健特征学习。我们评估了两个MLLMs（Qwen2-Audio-7B-Instruct和SALMONN）在两种评估模式下的表现：(a) 零样本和(b) 微调。实验结果表明，将音频与多提示方法结合可能是音频深度伪造检测的一种可行途径。实验结果显示，模型在没有任务特定训练的情况下表现不佳，并且难以泛化到领域外数据。然而，它们在领域内数据上仅需少量监督即可取得良好表现，这表明其在音频深度伪造检测中具有广阔的应用前景。</div>
</details>
</div>
<div class="card">
<div class="title">Brain network science modelling of sparse neural networks enables Transformers and LLMs to perform as fully connected</div>
<div class="meta-line">Authors: Yingtao Zhang, Diego Cerretti, Jialin Zhao, Wenjing Wu, Ziheng Liao, Umberto Michieli, Carlo Vittorio Cannistraci</div>
<div class="meta-line">First: 2025-01-31T13:04:37+00:00 · Latest: 2026-01-02T18:15:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.19107v3">Abs</a> · <a href="https://arxiv.org/pdf/2501.19107v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Dynamic sparse training (DST) can reduce the computational demands in ANNs, but faces difficulties in keeping peak performance at high sparsity levels. The Cannistraci-Hebb training (CHT) is a brain-inspired method for growing connectivity in DST. CHT leverages a gradient-free, topology-driven link regrowth, which has shown ultra-sparse (less than 1% connectivity) advantage across various tasks compared to fully connected networks. Yet, CHT suffers two main drawbacks: (i) its time complexity is $O(Nd^3)$ - N node network size, d node degree - restricting it to ultra-sparse regimes. (ii) it selects top link prediction scores, which is inappropriate for the early training epochs, when the network presents unreliable connections. Here, we design the first brain-inspired network model - termed bipartite receptive field (BRF) - to initialize the connectivity of sparse artificial neural networks. We further introduce a GPU-friendly matrix-based approximation of CH link prediction, reducing complexity to $O(N^3)$. We introduce the Cannistraci-Hebb training soft rule (CHTs), which adopts a flexible strategy for sampling connections in both link removal and regrowth, balancing the exploration and exploitation of network topology. Additionally, we integrate CHTs with a sigmoid gradual density decay (CHTss). Empirical results show that BRF offers performance advantages over previous network science models. Using 1% of connections, CHTs outperforms fully connected networks in MLP architectures on image classification tasks, compressing some networks to less than 30% of the nodes. Using 5% of the connections, CHTss outperforms fully connected networks in two Transformer-based machine translation tasks. Finally, at 30% connectivity, both CHTs and CHTss outperform other DST methods in language modeling task.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于稀疏神经网络的脑网络科学建模使Transformer和LLMs能够实现全连接网络的性能</div>
<div class="mono" style="margin-top:8px">动态稀疏训练（DST）可以降低人工神经网络（ANNs）的计算需求，但在保持高稀疏度下的峰值性能方面面临困难。Cannistraci-Hebb训练（CHT）是一种受大脑启发的方法，用于在DST中增强连接性。CHT利用一种无梯度、拓扑驱动的链接重生长策略，在各种任务中表现出优于全连接网络的超稀疏（连接度低于1%）优势。然而，CHT存在两个主要缺点：(i) 其时间复杂度为 $O(Nd^3)$ - N为网络节点数，d为节点度数 - 限制其仅适用于超稀疏范围；(ii) 它选择链接预测得分最高的连接，这在早期训练阶段不适用，因为此时网络连接不可靠。在此，我们设计了第一个受大脑启发的网络模型 - 称为双部分感受野（BRF） - 用于初始化稀疏人工神经网络的连接性。我们进一步引入了基于矩阵的CH链接预测的GPU友好型近似方法，将复杂度降低到 $O(N^3)$。我们提出了Cannistraci-Hebb训练软规则（CHTs），它采用了一种灵活的策略，在链接移除和重生长过程中进行连接采样，从而在网络拓扑的探索与利用之间取得平衡。此外，我们将CHTs与一个sigmoid渐进密度衰减（CHTss）相结合。实证结果表明，BRF在性能上优于之前的网络科学模型。在使用1%的连接时，CHTs在MLP架构的图像分类任务中优于全连接网络，将某些网络压缩到不到30%的节点。在使用5%的连接时，CHTss在两个基于Transformer的机器翻译任务中优于全连接网络。最后，在30%的连接度下，CHTs和CHTss在语言建模任务中均优于其他DST方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Dynamic sparse training (DST) can reduce the computational demands in ANNs, but faces difficulties in keeping peak performance at high sparsity levels.</div>
</details>
</div>
<div class="card">
<div class="title">LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization</div>
<div class="meta-line">Authors: Simon Paquette-Greenbaum, Jiangbo Yu</div>
<div class="meta-line">First: 2026-01-02T18:02:13+00:00 · Latest: 2026-01-02T18:02:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00770v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00770v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于组合有效前沿的LLM代理：投资组合优化</div>
<div class="mono" style="margin-top:8px">投资组合优化是所有主要金融机构进行的任务。卡方约束均值-方差投资组合优化（CCPO）问题表述在投资组合优化中非常普遍。这种类型的组合优化问题，即混合整数二次规划（MIQP）问题，其挑战来自于精确求解器难以处理解决方案的复杂性，因此通常采用启发式算法来寻找近似投资组合解。CCPO涉及许多繁琐且复杂的流程，同时也需要大量工作来开发启发式算法，其中多种启发式解的组合可以改善有效前沿。因此，常见的做法是开发多种启发式算法。代理框架在组合优化的许多问题中展现出有前景的潜力，因为它们在自动化大型流程方面已被证明同样高效，并且在算法开发方面表现出色，有时甚至超过人类水平。本研究实现了一种新颖的代理框架用于CCPO，并探讨了几种具体的架构。在基准问题中，所实现的代理框架与最先进的算法表现相当。此外，复杂流程和算法开发工作得到了缓解，而在最坏情况下，也报告了较低但可接受的误差。</div>
</details>
</div>
<div class="card">
<div class="title">C-VARC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models</div>
<div class="meta-line">Authors: Ping Wu, Guobin Shen, Dongcheng Zhao, Yuwei Wang, Yiting Dong, Yu Shi, Enmeng Lu, Feifei Zhao, Yi Zeng</div>
<div class="meta-line">First: 2025-06-02T09:56:59+00:00 · Latest: 2026-01-02T17:58:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.01495v5">Abs</a> · <a href="https://arxiv.org/pdf/2506.01495v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ensuring that Large Language Models (LLMs) align with mainstream human values and ethical norms is crucial for the safe and sustainable development of AI. Current value evaluation and alignment are constrained by Western cultural bias and incomplete domestic frameworks reliant on non-native rules; furthermore, the lack of scalable, rule-driven scenario generation methods makes evaluations costly and inadequate across diverse cultural contexts. To address these challenges, we propose a hierarchical value framework grounded in core Chinese values, encompassing three main dimensions, 12 core values, and 50 derived values. Based on this framework, we construct a large-scale Chinese Value Rule Corpus (C-VARC) containing over 250,000 value rules enhanced and expanded through human annotation. Experimental results demonstrate that scenarios guided by C-VARC exhibit clearer value boundaries and greater content diversity compared to those produced through direct generation. In the evaluation across six sensitive themes (e.g., surrogacy, suicide), seven mainstream LLMs preferred C-VARC generated options in over 70.5% of cases, while five Chinese human annotators showed an 87.5% alignment with C-VARC, confirming its universality, cultural relevance, and strong alignment with Chinese values. Additionally, we construct 400,000 rule-based moral dilemma scenarios that objectively capture nuanced distinctions in conflicting value prioritization across 17 LLMs. Our work establishes a culturally-adaptive benchmarking framework for comprehensive value evaluation and alignment, representing Chinese characteristics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>C-VARC：面向大语言模型价值对齐的大型中文价值规则语料库</div>
<div class="mono" style="margin-top:8px">确保大语言模型（LLMs）与主流人类价值观和伦理规范对齐，是AI安全和可持续发展的关键。当前的价值评估与对齐工作受到西方文化偏见和依赖非本土规则的不完整国内框架的限制；此外，缺乏可扩展的、基于规则的情景生成方法，使得评估在多元文化背景下成本高昂且不充分。为应对这些挑战，我们提出一个基于核心中国价值观的分层价值框架，涵盖三个主要维度、12个核心价值观和50个衍生价值观。基于此框架，我们构建了一个包含超过250,000条通过人工标注增强和扩展的价值规则语料库（C-VARC）。实验结果表明，由C-VARC引导的情景表现出更清晰的价值边界和更高的内容多样性，相较于直接生成的情景。在六个敏感主题（如代孕、自杀）的评估中，七种主流LLMs在超过70.5%的情况下更倾向于C-VARC生成的选项，而五位中国人工标注者与C-VARC的契合度达到87.5%，证实了其普适性、文化相关性和与中国价值观的高度一致。此外，我们构建了400,000条基于规则的道德困境情景，客观捕捉了17种LLMs在冲突价值优先级中的细微差异。我们的工作建立了一个文化适应性的基准框架，用于全面的价值评估与对齐，体现了中国特色。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Ensuring that Large Language Models (LLMs) align with mainstream human values and ethical norms is crucial for the safe and sustainable development of AI.</div>
</details>
</div>
<div class="card">
<div class="title">uGMM-NN: Univariate Gaussian Mixture Model Neural Network</div>
<div class="meta-line">Authors: Zakeria Sharif Ali</div>
<div class="meta-line">First: 2025-09-09T10:13:37+00:00 · Latest: 2026-01-02T17:57:38+00:00</div>
<div class="meta-line">Comments: 12 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.07569v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.07569v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces the Univariate Gaussian Mixture Model Neural Network (uGMM-NN), a novel neural architecture that embeds probabilistic reasoning directly into the computational units of deep networks. Unlike traditional neurons, which apply weighted sums followed by fixed non-linearities, each uGMM-NN node parameterizes its activations as a univariate Gaussian mixture, with learnable means, variances, and mixing coefficients. This design enables richer representations by capturing multimodality and uncertainty at the level of individual neurons, while retaining the scalability of standard feed-forward networks. We demonstrate that uGMM-NN can achieve competitive discriminative performance compared to conventional multilayer perceptrons, while additionally offering a probabilistic interpretation of activations. The proposed framework provides a foundation for integrating uncertainty-aware components into modern neural architectures, opening new directions for both discriminative and generative modeling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>uGMM-NN：单变量高斯混合模型神经网络</div>
<div class="mono" style="margin-top:8px">本文介绍了单变量高斯混合模型神经网络（uGMM-NN），这是一种新颖的神经架构，它将概率推理直接嵌入到深度网络的计算单元中。与传统的神经元不同，传统神经元应用加权和后接固定非线性函数，每个uGMM-NN节点将激活参数化为单变量高斯混合分布，具有可学习的均值、方差和混合系数。这种设计通过在单个神经元层面捕捉多模态性和不确定性，实现了更丰富的表示，同时保留了标准前馈网络的可扩展性。我们证明uGMM-NN在判别性能上可以与传统多层感知机相媲美，同时还能提供激活的的概率解释。所提出的框架为在现代神经架构中整合不确定性感知组件提供了基础，为判别和生成建模开辟了新的方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper introduces the Univariate Gaussian Mixture Model Neural Network (uGMM-NN), a novel neural architecture that embeds probabilistic reasoning directly into the computational units of deep networks.</div>
</details>
</div>
<div class="card">
<div class="title">Unified Primitive Proxies for Structured Shape Completion</div>
<div class="meta-line">Authors: Zhaiyu Chen, Yuqing Wang, Xiao Xiang Zhu</div>
<div class="meta-line">First: 2026-01-02T17:32:40+00:00 · Latest: 2026-01-02T17:32:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00759v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00759v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://unico-completion.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于结构化形状补全的统一基础体素代理</div>
<div class="mono" style="margin-top:8px">结构化形状补全通过基础体素而非无结构点来恢复缺失的几何信息，从而实现基于基础体素的表面重建。我们重新思考基础体素与点之间的交互方式，发现将基础体素解码到专门路径中，并关注共享形状特征更为有效。遵循这一原则，我们提出了UniCo，在单次前向传递中即可预测具有完整几何信息、语义信息和内点成员关系的基础体素集合。为了驱动这一统一表示，我们引入了基础体素代理，即可学习的查询，能够根据上下文生成可装配的输出。为确保一致的优化，我们的训练策略通过在线目标更新将基础体素与点耦合在一起。在四个独立的装配求解器下的合成与真实世界基准测试中，UniCo始终优于近期的基线方法，将Chamfer距离降低了最高50%，并将法向一致性提高了最高7%。这些结果为从不完整数据中实现结构化3D理解提供了一种有吸引力的方法。项目页面：https://unico-completion.github.io.</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction.</div>
</details>
</div>
<div class="card">
<div class="title">Clustering by Denoising: Latent plug-and-play diffusion for single-cell data</div>
<div class="meta-line">Authors: Dominik Meier, Shixing Yu, Sagnik Nandy, Promit Ghosal, Kyra Gan</div>
<div class="meta-line">First: 2025-10-26T21:03:56+00:00 · Latest: 2026-01-02T17:32:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.22835v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.22835v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) enables the study of cellular heterogeneity. Yet, clustering accuracy, and with it downstream analyses based on cell labels, remain challenging due to measurement noise and biological variability. In standard latent spaces (e.g., obtained through PCA), data from different cell types can be projected close together, making accurate clustering difficult. We introduce a latent plug-and-play diffusion framework that separates the observation and denoising space. This separation is operationalized through a novel Gibbs sampling procedure: the learned diffusion prior is applied in a low-dimensional latent space to perform denoising, while to steer this process, noise is reintroduced into the original high-dimensional observation space. This unique &quot;input-space steering&quot; ensures the denoising trajectory remains faithful to the original data structure. Our approach offers three key advantages: (1) adaptive noise handling via a tunable balance between prior and observed data; (2) uncertainty quantification through principled uncertainty estimates for downstream analysis; and (3) generalizable denoising by leveraging clean reference data to denoise noisier datasets, and via averaging, improve quality beyond the training set. We evaluate robustness on both synthetic and real single-cell genomics data. Our method improves clustering accuracy on synthetic data across varied noise levels and dataset shifts. On real-world single-cell data, our method demonstrates improved biological coherence in the resulting cell clusters, with cluster boundaries that better align with known cell type markers and developmental trajectories.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过去噪进行聚类：用于单细胞数据的潜在插拔式扩散模型</div>
<div class="mono" style="margin-top:8px">单细胞RNA测序（scRNA-seq）使得研究细胞异质性成为可能。然而，由于测量噪声和生物变异性，基于细胞标签的下游分析仍面临聚类准确性的挑战。在标准潜在空间（如通过PCA获得的空间）中，不同细胞类型的数据可能被投影到一起，使得准确聚类变得困难。我们引入了一种潜在插拔式扩散框架，将观测空间和去噪空间分离。这种分离通过一种新颖的Gibbs采样过程实现：学习到的扩散先验在低维潜在空间中用于去噪，同时为了引导这一过程，噪声被重新引入到原始的高维观测空间中。这种独特的&quot;输入空间引导&quot;确保了去噪轨迹忠实于原始数据结构。我们的方法提供了三个关键优势：（1）通过潜在先验和观测数据之间的可调节平衡实现自适应噪声处理；（2）通过原理性的不确定性估计为下游分析提供不确定性量化；（3）通过利用干净的参考数据对噪声更大的数据集进行去噪，并通过平均提高质量，从而实现可泛化的去噪。我们在合成数据和真实单细胞基因组数据上评估了方法的鲁棒性。我们的方法在不同噪声水平和数据集偏移的情况下，提高了合成数据的聚类准确性。在真实单细胞数据上，我们的方法展示了更符合已知细胞类型标记和发育轨迹的细胞聚类结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Single-cell RNA sequencing (scRNA-seq) enables the study of cellular heterogeneity.</div>
</details>
</div>
<div class="card">
<div class="title">Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics</div>
<div class="meta-line">Authors: Akash Samanta, Sheldon Williamson</div>
<div class="meta-line">First: 2025-12-30T19:57:52+00:00 · Latest: 2026-01-02T17:32:09+00:00</div>
<div class="meta-line">Comments: This preprint focuses on the theoretical framework and diagnostic behavior. Comprehensive experimental validation in application-specific settings is deferred to a companion experimental study</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.24445v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.24445v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference (TD) error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Within this framework, we introduce three diagnostic-driven instantiations: the Human-inspired Supervised Adaptive Optimizer (HSAO), Hybrid Error-Diagnostic Reinforcement Learning (HED-RL) for actor-critic methods, and the Meta-Learned Learning Policy (MLLP). Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to TD error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于偏差-噪声-对齐诊断的自适应学习</div>
<div class="mono" style="margin-top:8px">在非平稳和安全关键环境中部署的学习系统，当学习动态随时间演变时，常常面临不稳定、收敛缓慢或适应性脆弱的问题。尽管现代优化、强化学习和元学习方法能够适应梯度统计信息，但它们大多忽略了误差信号本身的时序结构。本文提出了一种诊断驱动的自适应学习框架，通过一个有原则的分解，显式建模误差演化，包括偏差（捕捉持续漂移）、噪声（捕捉随机变化）和对齐（捕捉重复方向激励导致的过冲）。这些诊断指标可在线计算，仅依赖于损失或时序差分（TD）误差轨迹的轻量级统计信息，且与模型结构或任务领域无关。我们展示了所提出的偏差-噪声-对齐分解为监督优化、演员-评论家强化学习和学习优化器提供了一个统一的控制基础。在此框架下，我们引入了三种基于诊断的实例化方法：受人类启发的监督自适应优化器（HSAO）、用于演员-评论家方法的混合误差诊断强化学习（HED-RL），以及元学习学习策略（MLLP）。在标准平滑性假设下，我们为所有情况建立了有界的有效更新和稳定性性质。在演员-评论家学习中的代表性诊断示例突显了所提出的信号如何根据TD误差结构调节适应性。总体而言，本工作将误差演化提升为自适应学习中的首要对象，并为在动态环境中实现可靠学习提供了可解释且轻量的基础。</div>
</details>
</div>
<div class="card">
<div class="title">Memory Bank Compression for Continual Adaptation of Large Language Models</div>
<div class="meta-line">Authors: Thomas Katraouras, Dimitrios Rafailidis</div>
<div class="meta-line">First: 2026-01-02T17:22:34+00:00 · Latest: 2026-01-02T17:22:34+00:00</div>
<div class="meta-line">Comments: Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC &#x27;26)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00756v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00756v1">PDF</a> · <a href="https://github.com/Thomkat/MBC">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于大语言模型持续适应的记忆银行压缩</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）已成为许多日常应用的核心。然而，随着数据的演变，其知识会迅速过时。持续学习旨在通过新信息更新LLMs，同时保留之前获得的知识。尽管全量微调等方法可以整合新数据，但计算成本高且容易出现灾难性遗忘，即先前知识被覆盖。通过为LLMs配备一个外部记忆模块（即记忆银行）来存储信息，记忆增强方法解决了这一问题。然而，这些方法在现实场景中面临关键限制，特别是当大规模数据流到来时，记忆银行会不断增长。在本文中，我们提出MBC模型，通过在线适应学习中的代码本优化策略压缩记忆银行。为了确保稳定学习，我们还引入了一种在线重置机制，防止代码本崩溃。此外，我们在LLM的注意力层中采用键值低秩适应，使压缩后的记忆表示能够高效利用。在基准问答数据集上的实验表明，与最具有竞争力的基线方法相比，MBC将记忆银行的大小减少到0.3%，同时在在线适应学习中保持了高知识保留准确率。我们的代码可在https://github.com/Thomkat/MBC上公开获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large Language Models (LLMs) have become a mainstay for many everyday applications.</div>
</details>
</div>
<div class="card">
<div class="title">A formal theory on problem space as a semantic world model in systems engineering</div>
<div class="meta-line">Authors: Mayuranath SureshKumar, Hanumanthrao Kannan</div>
<div class="meta-line">First: 2026-01-02T17:18:45+00:00 · Latest: 2026-01-02T17:18:45+00:00</div>
<div class="meta-line">Comments: Submitted to Wiley Systems Engineering Journal</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00755v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00755v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Classic problem-space theory models problem solving as a navigation through a structured space of states, operators, goals, and constraints. Systems Engineering (SE) employs analogous constructs (functional analysis, operational analysis, scenarios, trade studies), yet still lacks a rigorous systems-theoretic representation of the problem space itself. In current practice, reasoning often proceeds directly from stakeholder goals to prescriptive artifacts. This makes foundational assumptions about the operational environment, admissible interactions, and contextual conditions implicit or prematurely embedded in architectures or requirements. This paper addresses that gap by formalizing the problem space as an explicit semantic world model containing theoretical constructs that are defined prior to requirements and solution commitments. These constructs along with the developed axioms, theorems and corollary establish a rigorous criterion for unambiguous boundary semantics, context-dependent interaction traceability to successful stakeholder goal satisfaction, and sufficiency of problem-space specification over which disciplined reasoning can occur independent of solution design. It offers a clear distinction between what is true of the problem domain and what is chosen as a solution. The paper concludes by discussing the significance of the theory on practitioners and provides a dialogue-based hypothetical case study between a stakeholder and an engineer, demonstrating how the theory guides problem framing before designing any prescriptive artifacts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>关于系统工程中问题空间作为语义世界模型的形式理论</div>
<div class="mono" style="margin-top:8px">经典的问题空间理论将问题解决建模为在状态、操作符、目标和约束构成的结构化空间中的导航。系统工程（SE）采用了类似的构造（功能分析、运行分析、场景、权衡研究），但仍然缺乏对问题空间本身的严格系统理论表示。在当前实践中，推理往往直接从利益相关者目标推导出规范性成果。这使得对运行环境、可接受交互和上下文条件的基础假设变得隐含或过早地嵌入到架构或需求中。本文通过将问题空间形式化为一个显式的语义世界模型来填补这一空白，该模型包含在需求和解决方案承诺之前定义的理论构造。这些构造以及所发展的公理、定理和推论，为无歧义的边界语义、上下文相关的交互可追溯性以实现利益相关者目标的满足，以及能够独立于解决方案设计进行规范性推理提供了严格的准则。本文还明确区分了问题领域中真实存在的内容与作为解决方案的选择内容。最后，本文讨论了该理论对实践者的意义，并通过利益相关者与工程师之间的对话式假设案例研究，展示了该理论如何指导问题框架的构建，从而在设计任何规范性成果之前进行推理。</div>
</details>
</div>
<div class="card">
<div class="title">A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football</div>
<div class="meta-line">Authors: Sean Groom, Shuo Wang, Francisco Belo, Axl Rice, Liam Anderson</div>
<div class="meta-line">First: 2026-01-02T17:10:36+00:00 · Latest: 2026-01-02T17:10:36+00:00</div>
<div class="meta-line">Comments: 40 pages, 16 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00748v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00748v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating &quot;average&quot; behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种用于足球比赛中无球防守角色与表现评估的机器学习框架</div>
<div class="mono" style="margin-top:8px">评估足球比赛中的无球防守表现具有挑战性，因为传统指标无法捕捉那些限制对手行动选择和成功概率的细微协调性移动。尽管广泛使用的控球价值模型在评估带球动作方面表现出色，但它们在防守方面的应用仍有限。现有的反事实方法，如幽灵模型，有助于扩展这些分析，但通常依赖于模拟缺乏战术背景的&quot;平均&quot;行为。为了解决这一问题，我们引入了一种针对角球的协变量依赖隐藏马尔可夫模型（CDHMM）。我们的无标签模型直接从球员跟踪数据中推断出时间分辨的盯人和区域防守分配。我们利用这些分配提出了一种新的防守贡献归因框架，并提出了一种基于角色的幽灵方法，用于无球防守表现的反事实分析。我们展示了这些贡献如何提供一种可解释的评估方式，以对抗具有情境意识的基准。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities.</div>
</details>
</div>
<div class="card">
<div class="title">The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving</div>
<div class="meta-line">Authors: Max Ruiz Luyten, Mihaela van der Schaar</div>
<div class="meta-line">First: 2026-01-02T17:10:31+00:00 · Latest: 2026-01-02T17:10:31+00:00</div>
<div class="meta-line">Comments: 56 pages, 9 figures, submitted to Twenty-Ninth Annual Conference on Artificial Intelligence and Statistics</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00747v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00747v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model&#x27;s distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推理与创造力的权衡：迈向以创造力驱动的问题解决</div>
<div class="mono" style="margin-top:8px">当前最先进的大型语言模型（LLM）流水线依赖于引导式推理循环：采样多样化的思维链并强化得分最高的部分，主要优化正确性。我们分析了这种设计选择如何对模型在推理路径上的分布崩溃敏感，从而降低语义熵并损害创造性问题解决。为分析这一失败，我们引入了分布式创造性推理（DCR），这是一种统一的变分目标，将训练视为通过解决方案轨迹的概率测度进行梯度流。STaR、GRPO、DPO以及熵奖励等方法，都是同一损失函数的特殊情形。该框架提供了三个核心结果：(i) 正确性导向目标导致STaR、GRPO和DPO出现不同模式的多样性衰减定理；(ii) 确保收敛到稳定且多样策略的设计；(iii) 实践中实现这一目标的简单可行方法。因此，DCR为LLM提供了首个基于原理的配方，使其在保持正确性的同时也具备创造力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness.</div>
</details>
</div>
<div class="card">
<div class="title">Braiding vineyards</div>
<div class="meta-line">Authors: Erin Chambers, Christopher Fillmore, Elizabeth Stephenson, Mathijs Wintraecken</div>
<div class="meta-line">First: 2025-04-15T14:02:59+00:00 · Latest: 2026-01-02T17:05:15+00:00</div>
<div class="meta-line">Comments: 30 pages, 18 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.11203v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.11203v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we introduce and study what we believe is an intriguing and, to the best of our knowledge, previously unknown connection between two areas in computational topology, topological data analysis (TDA) and knot theory. Given a function from a topological space to $\mathbb{R}$, TDA provides tools to simplify and study the importance of topological features: in particular, the $l^{th}$-dimensional persistence diagram encodes the $l$-homology in the sublevel set as the function value increases as a set of points in the plane. Given a continuous one-parameter family of such functions, we can combine the persistence diagrams into an object known as a vineyard, which track the evolution of points in the persistence diagram. If we further restrict that family of functions to be periodic, we identify the two ends of the vineyard, yielding a closed vineyard. This allows the study of monodromy, which in this context means that following the family of functions for a period permutes the set of points in a non-trivial way. In this work, given a link and value $l$, we construct a topological space and periodic family of functions such that the closed $l$-vineyard contains this link. This shows that vineyards are topologically as rich as one could possibly hope. Importantly, it has at least two immediate consequences: First, monodromy of any periodicity can occur in a $l$-vineyard, answering a variant of a question by [Arya et al 2024]. To exhibit this, we also reformulate monodromy in a more geometric way, which may be of interest in itself. Second, distinguishing vineyards is likely to be difficult given the known difficulty of knot and link recognition, which have strong connections to many NP-hard problems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>交织的葡萄园</div>
<div class="mono" style="margin-top:8px">在这项工作中，我们介绍并研究我们认为在计算拓扑学的两个领域——拓扑数据分析（TDA）和纽结理论之间存在一种引人入胜且据我们所知此前未知的联系。给定一个从拓扑空间到 $\mathbb{R}$ 的函数，TDA 提供了简化和研究拓扑特征重要性的工具：特别是，$l^{th}$ 维的持久性图（persistence diagram）将函数值增加时子水平集中的 $l$-同调编码为平面上的一组点。给定一个连续的一参数函数族，我们可以将这些持久性图合并为一个称为葡萄园（vineyard）的对象，它追踪持久性图中点的演化过程。如果我们进一步将该函数族限制为周期性的，就可以识别葡萄园的两个端点，从而得到一个闭合的葡萄园。这使得我们可以研究单值化（monodromy），即在该函数族经历一个周期后，点集会发生非平凡的排列。在这项工作中，给定一个链环（link）和一个值 $l$，我们构造了一个拓扑空间和一个周期函数族，使得闭合的 $l$-葡萄园包含该链环。这表明葡萄园在拓扑上可以达到人们可能期望的丰富程度。重要的是，这至少有两个直接的后果：首先，任何周期性的单值化都可以在 $l$-葡萄园中出现，回答了 [Arya 等人 2024] 提出的一个变体问题。为了展示这一点，我们还以更几何的方式重新表述了单值化，这本身可能具有研究价值。其次，鉴于已知的纽结和链环识别问题的难度，区分葡萄园可能同样困难，而这些问题与许多 NP 难问题有紧密联系。</div>
</details>
</div>
<div class="card">
<div class="title">Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs</div>
<div class="meta-line">Authors: Jing Yang Lee, Kong-Aik Lee, Woon-Seng Gan</div>
<div class="meta-line">First: 2025-06-18T04:19:33+00:00 · Latest: 2026-01-02T17:03:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.15131v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.15131v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby multiple appropriate responses exist for a single dialogue context. Despite prior research showing that modeling this property boosts response diversity, most modern LLM-based dialogue agents do not explicitly do so. In this work, we model the o2m property of OD in LLMs by decomposing OD generation into two key tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS), which entail generating a set of n semantically and lexically diverse high-quality responses for a given dialogue context, followed by selecting a single response based on human preference, respectively. To facilitate MRG and PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the o2m property by featuring multiple plausible responses for each context. Leveraging o2mDial, we propose new in-context learning and instruction-tuning strategies, as well as novel evaluation metrics for MRG, alongside a model-based approach for PS. Empirical results demonstrate that applying the proposed two-stage framework to smaller LLMs for OD generation enhances overall response diversity while maintaining contextual coherence, improving response quality by up to 90%, bringing them closer to the performance of larger models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用大语言模型建模开放域对话中的多对一属性</div>
<div class="mono" style="margin-top:8px">开放域对话（OD）具有多对一（o2m）属性，即对于一个对话上下文可能存在多个合适的回应。尽管已有研究表明建模这一属性可以提升回应的多样性，但大多数现代基于大语言模型（LLM）的对话代理并未显式地进行此类建模。在本工作中，我们通过将OD生成分解为两个关键任务：多回应生成（MRG）和基于偏好的选择（PS），来建模OD中的o2m属性。MRG任务要求为给定的对话上下文生成一组n个语义和词汇上多样的高质量回应，而PS任务则基于人类偏好选择一个最终回应。为了促进MRG和PS，我们引入了o2mDial，一个专门设计用于捕捉o2m属性的对话语料库，其特点是在每个上下文中包含多个合理的回应。借助o2mDial，我们提出了新的上下文学习和指令调优策略，并设计了针对MRG的新型评估指标，以及基于模型的PS方法。实证结果表明，将所提出的两阶段框架应用于较小的LLM进行OD生成，可以提升整体回应多样性，同时保持上下文连贯性，回应质量可提高高达90%，接近大型模型的性能。</div>
</details>
</div>
<div class="card">
<div class="title">On the modeling of irreversibility by relaxator Liouville dynamics</div>
<div class="meta-line">Authors: Janos Hajdu, Martin Janßen</div>
<div class="meta-line">First: 2025-10-09T11:13:01+00:00 · Latest: 2026-01-02T17:00:01+00:00</div>
<div class="meta-line">Comments: 54 pages, 3 figures, submitted to Ann. Phys. (Berlin)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.08083v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.08083v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A general approach to modeling irreversibility starting from microscopic reversibility is presented. The time $t_s$ up to which relevant degrees of freedom of a system are tracked is extremely much shorter than the spectral resolution time $t_e$ that would be necessary to resolve the spectrum of all degrees of freedom involved. A relaxator that breaks reversibility condenses in the Liouville operator of the relevant degrees of freedom. The irrelevant degrees of freedom act as an environment to the system. The irreversible relaxator Liouville equation contains memory effects and initial correlations of all degrees of freedom. Stationary states turn out to be generically unique and independent of the initial conditions and exceptions are due to degeneracies. Equilibrium states lie in the relaxator&#x27;s kernel yielding a stationary Pauli master equation. Kinetic equations for oneparticle densities are constructed as special cases of relaxator Liouville dynamics. Kubo&#x27;s linear response theory is generalized to relaxator Liouville dynamics and related to irreversibility within the system. In a weak coupling approximation between system and environment the relaxator can be reduced to environmental correlations and bilinear system operators. Markov approximation turns the relaxator Liouville dynamics into a semi-group dynamics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>关于通过弛豫李奥维ille动力学建模不可逆性的研究</div>
<div class="mono" style="margin-top:8px">本文提出了一种从微观可逆性出发建模不可逆性的通用方法。系统中相关自由度被追踪的时间 $t_s$ 极其短于为解析所有涉及自由度的谱所需的谱分辨时间 $t_e$。一个破坏可逆性的弛豫子会凝聚在相关自由度的李奥维ille算符中。不相关的自由度则作为系统的环境。不可逆的弛豫李奥维ille方程包含所有自由度的记忆效应和初始关联。稳态通常唯一且与初始条件无关，例外情况源于简并。平衡态位于弛豫子的核中，从而得到一个稳态的泡利主方程。单粒子密度的运动方程作为弛豫李奥维ille动力学的特例被构造出来。Kubo的线性响应理论被推广到弛豫李奥维ille动力学，并与系统内的不可逆性相关联。在系统与环境之间弱耦合近似下，弛豫子可被简化为环境关联和双线性系统算符。马尔可夫近似将弛豫李奥维ille动力学转化为半群动力学。</div>
</details>
</div>
<div class="card">
<div class="title">An Agentic Framework for Neuro-Symbolic Programming</div>
<div class="meta-line">Authors: Aliakbar Nafar, Chetan Chigurupati, Danial Kamali, Hamid Karimian, Parisa Kordjamshidi</div>
<div class="meta-line">First: 2026-01-02T16:59:39+00:00 · Latest: 2026-01-02T16:59:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00743v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.00743v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library&#x27;s specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种用于神经符号编程的代理框架</div>
<div class="mono" style="margin-top:8px">将符号约束整合到深度学习模型中可以使它们更加稳健、可解释且数据高效。然而，这一过程仍然耗时且具有挑战性。现有的框架如DomiKnowS通过提供高级声明式编程接口来帮助这一整合，但它们仍然假设用户熟悉库的特定语法。我们提出AgenticDomiKnowS（ADS）以消除这种依赖。ADS使用一种代理工作流，将自由形式的任务描述翻译成完整的DomiKnowS程序，并分别创建和测试每个DomiKnowS组件。该工作流支持可选的人机交互干预，使熟悉DomiKnowS的用户能够优化中间输出。我们展示了ADS如何使有经验的DomiKnowS用户和非用户快速构建神经符号程序，将开发时间从数小时缩短到10-15分钟。</div>
</details>
</div>
<div class="card">
<div class="title">QUITE: A Query Rewrite System Beyond Rules with LLM Agents</div>
<div class="meta-line">Authors: Yuyang Song, Hanxu Yan, Jiale Lao, Yibo Wang, Yufei Li, Yuanchun Zhou, Jianguo Wang, Mingjie Tang</div>
<div class="meta-line">First: 2025-06-09T11:51:27+00:00 · Latest: 2026-01-02T16:51:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.07675v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.07675v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently. Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions. This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules. Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules. Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries. To address this issue, we propose QUITE (query rewrite), a training-free and feedback-aware system based on LLM agents that rewrites SQL queries into semantically equivalent forms with significantly better performance, covering a broader range of query patterns and rewrite strategies compared to rule-based methods. Firstly, we design a multi-agent framework controlled by a finite state machine (FSM) to equip LLMs with the ability to use external tools and enhance the rewrite process with real-time database feedback. Secondly, we develop a rewrite middleware to enhance the ability of LLMs to generate optimized query equivalents. Finally, we employ a novel hint injection technique to improve execution plans for rewritten queries. Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>QUITE：一种超越规则的SQL查询重写系统，基于LLM代理</div>
<div class="mono" style="margin-top:8px">查询重写将SQL查询转换为语义等价但执行效率更高的形式。现有方法主要依赖预定义的重写规则，但它们只能处理有限的查询子集，并可能导致性能下降。这种限制源于基于规则的查询重写的三个挑战：(1) 发现和验证新规则较为困难，(2) 固定的重写规则无法泛化到新的查询模式，(3) 一些重写技术无法用固定规则表达。鉴于人类专家在重写能力上显著更强但存在可扩展性问题，而大型语言模型（LLMs）已展现出接近人类水平的语义理解和推理能力，我们提出了一种使用LLMs进行超越规则的SQL查询重写的新方法。由于LLMs存在幻觉问题，直接应用它们通常会导致非等价或次优的查询。为了解决这一问题，我们提出了QUITE（查询重写），一个无需训练且具备反馈感知的系统，基于LLM代理，将SQL查询重写为语义等价但性能显著更好的形式，覆盖比基于规则的方法更广泛的查询模式和重写策略。首先，我们设计了一个由有限状态机（FSM）控制的多代理框架，使LLMs能够使用外部工具，并通过实时数据库反馈增强重写过程。其次，我们开发了一种重写中间件，以增强LLMs生成优化查询等价物的能力。最后，我们采用了一种新颖的提示注入技术，以改进重写查询的执行计划。大量实验表明，QUITE在现有最先进的方法上将查询执行时间减少了高达35.8%，并比之前的方法多生成24.1%的重写，覆盖了早期系统未处理的查询案例。</div>
</details>
</div>
<div class="card">
<div class="title">Med-2D SegNet: A Light Weight Deep Neural Network for Medical 2D Image Segmentation</div>
<div class="meta-line">Authors: Lameya Sabrin, Md. Sanaullah Chowdhury, Salauddin Tapu, Noyon Kumar Sarkar, Ferdous Bin Ali</div>
<div class="meta-line">First: 2025-04-20T19:04:43+00:00 · Latest: 2026-01-02T16:47:20+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.14715v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.14715v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate and efficient medical image segmentation is crucial for advancing clinical diagnostics and surgical planning, yet remains a complex challenge due to the variability in anatomical structures and the demand for low-complexity models. In this paper, we introduced Med-2D SegNet, a novel and highly efficient segmentation architecture that delivers outstanding accuracy while maintaining a minimal computational footprint. Med-2D SegNet achieves state-of-the-art performance across multiple benchmark datasets, including KVASIR-SEG, PH2, EndoVis, and GLAS, with an average Dice similarity coefficient (DSC) of 89.77% across 20 diverse datasets. Central to its success is the compact Med Block, a specialized encoder design that incorporates dimension expansion and parameter reduction, enabling precise feature extraction while keeping model parameters to a low count of just 2.07 million. Med-2D SegNet excels in cross-dataset generalization, particularly in polyp segmentation, where it was trained on KVASIR-SEG and showed strong performance on unseen datasets, demonstrating its robustness in zero-shot learning scenarios, even though we acknowledge that further improvements are possible. With top-tier performance in both binary and multi-class segmentation, Med-2D SegNet redefines the balance between accuracy and efficiency, setting a new benchmark for medical image analysis. This work paves the way for developing accessible, high-performance diagnostic tools suitable for clinical environments and resource-constrained settings, making it a step forward in the democratization of advanced medical technology.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Med-2D SegNet：一种轻量级深度神经网络用于医学二维图像分割</div>
<div class="mono" style="margin-top:8px">准确且高效的医学图像分割对于推进临床诊断和手术规划至关重要，但由于解剖结构的可变性和对低复杂度模型的需求，这仍然是一个复杂的挑战。本文中，我们引入了Med-2D SegNet，这是一种新颖且高效的分割架构，能够在保持最小计算开销的同时提供卓越的准确性。Med-2D SegNet在多个基准数据集上实现了最先进的性能，包括KVASIR-SEG、PH2、EndoVis和GLAS，在20个多样化数据集上的平均Dice相似性系数（DSC）达到89.77%。其成功的关键在于紧凑的Med Block，这是一种专门设计的编码器，通过维度扩展和参数减少，实现了精确的特征提取，同时将模型参数量控制在仅207万的低水平。Med-2D SegNet在跨数据集泛化方面表现出色，特别是在息肉分割任务中，它在KVASIR-SEG上进行训练，并在未见过的数据集上展现出强大的性能，证明了其在零样本学习场景中的鲁棒性，尽管我们承认仍有进一步改进的空间。在二分类和多分类分割任务中均表现出顶级性能，Med-2D SegNet重新定义了准确性和效率之间的平衡，为医学图像分析设立了新的基准。这项工作为开发适用于临床环境和资源受限场景的可访问、高性能诊断工具铺平了道路，是先进医学技术普及化的重要一步。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate and efficient medical image segmentation is crucial for advancing clinical diagnostics and surgical planning, yet remains a complex challenge due to the variability in anatomical structures and the demand for low-complexity models.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260105_0351.html">20260105_0351</a>
<a href="archive/20260104_0353.html">20260104_0353</a>
<a href="archive/20260103_0351.html">20260103_0351</a>
<a href="archive/20260102_0354.html">20260102_0354</a>
<a href="archive/20260101_0352.html">20260101_0352</a>
<a href="archive/20251231_0356.html">20251231_0356</a>
<a href="archive/20251230_0356.html">20251230_0356</a>
<a href="archive/20251229_0355.html">20251229_0355</a>
<a href="archive/20251228_0354.html">20251228_0354</a>
<a href="archive/20251227_0355.html">20251227_0355</a>
<a href="archive/20251226_0355.html">20251226_0355</a>
<a href="archive/20251225_0355.html">20251225_0355</a>
<a href="archive/20251224_0355.html">20251224_0355</a>
<a href="archive/20251223_0354.html">20251223_0354</a>
<a href="archive/20251222_0354.html">20251222_0354</a>
<a href="archive/20251221_0354.html">20251221_0354</a>
<a href="archive/20251220_0356.html">20251220_0356</a>
<a href="archive/20251219_0354.html">20251219_0354</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0346.html">20251217_0346</a>
<a href="archive/20251216_0347.html">20251216_0347</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
