<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-20 03:52</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260120_0352</div>
    <div class="row"><div class="card">
<div class="title">Simulating Image Coaddition with the Nancy Grace Roman Space Telescope. IV. Hyperparameter Optimization and Experimental Features</div>
<div class="meta-line">Authors: Kaili Cao, Christopher M. Hirata, Katherine Laliotis, Masaya Yamamoto, Emily Macbeth, M. A. Troxel</div>
<div class="meta-line">First: 2025-09-22T18:13:58+00:00 · Latest: 2026-01-16T18:59:59+00:00</div>
<div class="meta-line">Comments: 25 pages, 10 figures, matches version accepted by ApJ</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18286v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.18286v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">For weak gravitational lensing cosmology with the forthcoming Nancy Grace Roman Space Telescope, image coaddition, or construction of oversampled images from undersampled ones, is a critical step in the image processing pipeline. In the previous papers in this series, we have re-implemented the {\sc Imcom} algorithm, which offers control over point spread functions in coadded images, and applied it to state-of-the-art image simulations for Roman. In this work, we systematically investigate the impact of {\sc Imcom} hyperparameters on the quality of measurement results. We re-coadd the same $16$ blocks ($1.75 \times 1.75 \,{\rm arcmin}^2$, $2688 \times 2688$ pixels each) from OpenUniverse2024 simulations with $26$ different configurations in each of $5$ bands. We then compare the results in terms of $12$ objective evaluation criteria, including internal diagnostics of {\sc Imcom}, properties of coadded noise frames, measurements of injected point sources, and time consumption. We demonstrate that: i) the Cholesky kernel is the best known linear algebra strategy for {\sc Imcom}, ii) for our measurements, a wide Gaussian target output PSF outperforms a smoothed Airy disk or a narrow Gaussian, iii) kernel-specific settings are worth considering for future coaddition, and iv) {\sc Imcom} experimental features studied in this work are either inconsequential or detrimental. We end this paper by discussing current and next steps of {\sc Imcom}-related studies in the context of Roman shear and clustering measurements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用南希·格蕾丝·罗曼太空望远镜模拟图像叠加。IV. 超参数优化与实验特性</div>
<div class="mono" style="margin-top:8px">对于即将推出的南希·格蕾丝·罗曼太空望远镜的弱引力透镜宇宙学研究，图像叠加，即从欠采样图像构建超采样图像，是图像处理流程中的关键步骤。在本系列的前几篇论文中，我们重新实现了{\sc Imcom}算法，该算法在叠加图像中提供了对点扩散函数的控制，并将其应用于罗曼望远镜的尖端图像模拟。在本工作中，我们系统地研究了{\sc Imcom}超参数对测量结果质量的影响。我们使用OpenUniverse2024模拟的相同$16$个块（每个块为$1.75 \times 1.75 \,{\rm arcmin}^2$，$2688 \times 2688$像素）在5个波段中分别采用26种不同配置进行重新叠加。然后，我们根据12项客观评估标准比较结果，包括{\sc Imcom}的内部诊断、叠加噪声帧的特性、注入点源的测量以及时间消耗。我们证明：i) 胆固醇核是{\sc Imcom}中已知的最佳线性代数策略；ii) 对于我们的测量，宽高斯目标输出PSF优于平滑艾里光斑或窄高斯；iii) 未来叠加中应考虑核特定设置；iv) 本工作中研究的{\sc Imcom}实验特性要么无关紧要，要么有害。最后，我们讨论了在罗曼剪切和聚类测量背景下，与{\sc Imcom}相关的当前和下一步研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">For weak gravitational lensing cosmology with the forthcoming Nancy Grace Roman Space Telescope, image coaddition, or construction of oversampled images from undersampled ones, is a critical step in the image processing pipeline.</div>
</details>
</div>
<div class="card">
<div class="title">UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation</div>
<div class="meta-line">Authors: Ruiheng Zhang, Jingfeng Yao, Huangxuan Zhao, Hao Yan, Xiao He, Lei Chen, Zhou Wei, Yong Luo, Zengmao Wang, Lefei Zhang, Dacheng Tao, Bo Du</div>
<div class="meta-line">First: 2026-01-16T18:59:58+00:00 · Latest: 2026-01-16T18:59:58+00:00</div>
<div class="meta-line">Comments: Codes and models are available at https://github.com/ZrH42/UniX</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11522v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11522v1">PDF</a> · <a href="https://github.com/ZrH42/UniX">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniX：统一自回归与扩散模型用于胸部X光理解与生成</div>
<div class="mono" style="margin-top:8px">尽管近期取得了进展，医疗基础模型在统一视觉理解和生成任务方面仍面临挑战，因为这两个任务具有本质上冲突的目标：语义抽象与像素级重建。现有方法通常基于参数共享的自回归架构，常导致其中一个或两个任务的性能受损。为了解决这一问题，我们提出了UniX，这是一个下一代统一的医疗基础模型，用于胸部X光的理解与生成。UniX将两个任务解耦，分别采用自回归分支进行理解，以及扩散分支进行高保真生成。关键的是，引入了一种跨模态的自注意力机制，以动态方式利用理解特征引导生成过程。结合严谨的数据清洗流程和多阶段训练策略，该架构实现了任务间的协同合作，同时利用扩散模型的优势实现更优的生成效果。在两个代表性基准测试中，UniX在理解性能（Micro-F1）上提升了46.1%，在生成质量（FD-RadDino）上提高了24.2%，仅使用LLM-CXR参数量的四分之一。通过达到与任务专用模型相当的性能，我们的工作建立了一个可扩展的范式，用于医疗图像的理解与生成。代码和模型可在https://github.com/ZrH42/UniX获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction.</div>
</details>
</div>
<div class="card">
<div class="title">How Long Is a Piece of String? A Brief Empirical Analysis of Tokenizers</div>
<div class="meta-line">Authors: Jonathan Roberts, Kai Han, Samuel Albanie</div>
<div class="meta-line">First: 2026-01-16T18:58:29+00:00 · Latest: 2026-01-16T18:58:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11518v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11518v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier LLMs are increasingly utilised across academia, society and industry. A commonly used unit for comparing models, their inputs and outputs, and estimating inference pricing is the token. In general, tokens are used as a stable currency, assumed to be broadly consistent across tokenizers and contexts, enabling direct comparisons. However, tokenization varies significantly across models and domains of text, making naive interpretation of token counts problematic. We quantify this variation by providing a comprehensive empirical analysis of tokenization, exploring the compression of sequences to tokens across different distributions of textual data. Our analysis challenges commonly held heuristics about token lengths, finding them to be overly simplistic. We hope the insights of our study add clarity and intuition toward tokenization in contemporary LLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一根绳子有多长？对分词器的简要实证分析</div>
<div class="mono" style="margin-top:8px">前沿的大语言模型（LLMs）在学术界、社会和工业领域正被越来越多地使用。在比较模型、输入和输出以及估算推理定价时，通常使用token作为单位。一般来说，token被用作一种稳定的货币单位，假设其在不同分词器和上下文中具有广泛的一致性，从而实现直接比较。然而，不同模型和文本领域中的分词方式存在显著差异，使得对token数量的简单解释变得有问题。我们通过提供对分词的全面实证分析来量化这种差异，探讨在不同文本数据分布下序列如何被压缩为token。我们的分析挑战了关于token长度的常见启发式假设，发现这些假设过于简单。我们希望本研究的见解能为当前大语言模型中的分词提供更清晰的理解和直觉。</div>
</details>
</div>
<div class="card">
<div class="title">Do explanations generalize across large reasoning models?</div>
<div class="meta-line">Authors: Koyena Pal, David Bau, Chandan Singh</div>
<div class="meta-line">First: 2026-01-16T18:55:29+00:00 · Latest: 2026-01-16T18:55:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11517v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11517v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>解释是否能在大型推理模型之间泛化？</div>
<div class="mono" style="margin-top:8px">大型推理模型（LRMs）在解决问题的过程中会产生一个文本形式的推理链（CoT），这可以作为理解问题的潜在强大工具，通过呈现人类可读的自然语言解释。然而，尚不清楚这些解释是否具有泛化能力，即它们是否捕捉了问题背后的普遍模式，而不是仅对LRM特有的模式。这是理解或发现新概念（例如在科学AI中）的关键问题。我们通过评估一种特定的泛化性概念来研究这一泛化问题：即由一个LRM生成的解释是否在提供给其他LRMs时能产生相同的行为。我们发现，CoT解释通常表现出这种形式的泛化（即它们增加了LRMs之间的一致性），并且这种泛化能力与人类偏好排名以及强化学习微调相关。我们进一步分析了解释产生一致答案的条件，并提出了一种简单且基于句子的集成策略，以提高一致性。综上所述，这些结果提醒我们在使用LRM解释以获得新见解时应保持谨慎，并概述了用于描述LRM解释泛化性的框架。</div>
</details>
</div>
<div class="card">
<div class="title">Building Production-Ready Probes For Gemini</div>
<div class="meta-line">Authors: János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy</div>
<div class="meta-line">First: 2026-01-16T18:54:29+00:00 · Latest: 2026-01-16T18:54:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11516v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11516v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architecture that handle this long-context distribution shift.
  We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant shifts, including multi-turn conversations, static jailbreaks, and adaptive red teaming. Our results demonstrate that while multimax addresses context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes.
  These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google&#x27;s frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>为Gemini构建生产就绪型探针</div>
<div class="mono" style="margin-top:8px">前沿语言模型的能力正在迅速提升。因此，我们需要更强的措施来防止恶意行为者滥用日益强大的系统。先前的研究表明，激活探针可能是应对滥用的一种有前景的技术，但我们发现了一个关键的挑战：现有探针在重要的生产分布变化下无法泛化。特别是，我们发现从短上下文到长上下文输入的转变对现有探针架构来说具有挑战性。我们提出了几种新的探针架构，以处理这种长上下文分布变化。
我们评估了这些探针在网络安全攻击领域的表现，测试其在多种生产相关分布变化下的鲁棒性，包括多轮对话、静态 jailbreak 和适应性红队攻击。我们的结果表明，虽然 multimax 能够处理上下文长度的问题，但为了实现广泛的泛化，需要结合架构选择和在多样化分布上的训练。此外，我们还展示了将探针与提示分类器结合可以以较低成本实现最优准确率，这得益于探针的计算效率。
这些发现已用于Gemini（谷歌的前沿语言模型）用户端实例中，成功部署了滥用缓解探针。最后，我们发现使用AlphaEvolve自动化改进探针架构搜索和适应性红队攻击取得了初步积极成果，表明某些AI安全研究的自动化已经成为可能。</div>
</details>
</div>
<div class="card">
<div class="title">Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors</div>
<div class="meta-line">Authors: Antar Kumar Biswas, Masoud H. Nazari</div>
<div class="meta-line">First: 2025-12-27T20:30:07+00:00 · Latest: 2026-01-16T18:53:25+00:00</div>
<div class="meta-line">Comments: This is a preprint of a manuscript currently under review at Electric Power Systems Research. The content may be subject to change following peer review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22699v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.22699v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a novel learning based framework for predicting power outages caused by extreme events. The proposed approach targets low probability high consequence outage scenarios and leverages a comprehensive set of features derived from publicly available data sources. We integrate EAGLE-I outage records from 2014 to 2024 with weather, socioeconomic, infrastructure, and seasonal event data. Incorporating social and demographic indicators reveals patterns of community vulnerability and improves understanding of outage risk during extreme conditions. Four machine learning models are evaluated including Random Forest (RF), Graph Neural Network (GNN), Adaptive Boosting (AdaBoost), and Long Short Term Memory (LSTM). Experimental validation is performed on a large scale dataset covering counties in the lower peninsula of Michigan. Among all models tested, the LSTM network achieves higher accuracy.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>极端事件期间停电的预测建模：整合天气和社会经济因素</div>
<div class="mono" style="margin-top:8px">本文提出了一种基于学习的新框架，用于预测由极端事件引起的停电。该方法针对低概率高影响的停电场景，并利用从公开数据源获得的综合特征集。我们整合了2014年至2024年的EAGLE-I停电记录，结合了天气、社会经济、基础设施和季节性事件数据。引入社会和人口统计指标揭示了社区脆弱性的模式，并提高了对极端条件期间停电风险的理解。评估了四种机器学习模型，包括随机森林（RF）、图神经网络（GNN）、自适应提升（AdaBoost）和长短期记忆网络（LSTM）。实验验证基于密歇根州下半岛各县的大规模数据集。在所有测试模型中，LSTM网络实现了更高的准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Strong Solutions and Quantization-Based Numerical Schemes for a Class of Non-Markovian Volatility Models</div>
<div class="meta-line">Authors: Martino Grasselli, Gilles Pagès</div>
<div class="meta-line">First: 2025-02-28T23:21:44+00:00 · Latest: 2026-01-16T18:51:33+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.00243v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.00243v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We investigate a class of non-Markovian processes that hold particular relevance in the realm of mathematical finance. This family encompasses path-dependent volatility models, including those pioneered by [Platen and Rendek, 2018] and, more recently, by [Guyon and Lekeufack, 2023]. Our study unfolds in two principal phases. In the first phase, we introduce a functional quantization scheme based on an extended version of the Lamperti transformation that we propose to handle the presence of a memory term incorporated into the diffusion coefficient. In the second phase, we study the problem of existence and uniqueness of a strong solution for the SDEs related to the examples that motivate our study, in order to provide a theoretical basis to correctly apply the proposed numerical schemes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一类非马尔可夫波动模型的强解与基于量化的方法</div>
<div class="mono" style="margin-top:8px">我们研究了一类在数学金融领域具有特别相关性的非马尔可夫过程。该家族包括路径依赖型波动模型，如[Platen和Rendek, 2018]以及更近期的[Guyon和Lekeufack, 2023]所提出的模型。我们的研究分为两个主要阶段。第一阶段，我们引入了一种基于扩展版Lamperti变换的函数量化方案，以处理包含在扩散系数中的记忆项。第二阶段，我们研究了与激发我们研究的示例相关的随机微分方程（SDEs）的强解存在性和唯一性问题，以提供正确应用所提出数值方案的理论基础。</div>
</details>
</div>
<div class="card">
<div class="title">ShapeR: Robust Conditional 3D Shape Generation from Casual Captures</div>
<div class="meta-line">Authors: Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins, Daniel DeTone, Pierre Moulon, Qirui Wu, Zhengqin Li, Julian Straub, Richard Newcombe, Jakob Engel</div>
<div class="meta-line">Venue: www</div>
<div class="meta-line">First: 2026-01-16T18:51:24+00:00 · Latest: 2026-01-16T18:51:24+00:00</div>
<div class="meta-line">Comments: Project Page: http://facebookresearch.github.io/ShapeR Video: https://www.youtube.com/watch?v=EbY30KAA55I</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11514v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11514v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="http://facebookresearch.github.io/ShapeR">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ShapeR：从随意捕捉序列中生成鲁棒的条件3D形状</div>
<div class="mono" style="margin-top:8px">近年来，3D形状生成取得了令人印象深刻的结果，但大多数现有方法依赖于干净、无遮挡且良好分割的输入。这些条件在现实场景中很少被满足。我们提出了ShapeR，这是一种新颖的方法，用于从随意捕捉的序列中生成条件3D物体形状。给定一个图像序列，我们利用现成的视觉惯性SLAM、3D检测算法和视觉语言模型，提取每个物体的一组稀疏SLAM点、多视角图像以及机器生成的描述。一个经过校正的流变换器通过有效利用这些模态进行条件建模，生成高保真度的度量3D形状。为了确保对随意捕捉数据挑战的鲁棒性，我们采用了一系列技术，包括实时组合增强、跨越物体和场景级别的课程训练方案，以及处理背景杂乱的策略。此外，我们引入了一个新的评估基准，包含7个现实场景中178个野外物体的几何标注。实验表明，在这种具有挑战性的设置下，ShapeR显著优于现有方法，其Chamfer距离相比最先进的方法提升了2.7倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs.</div>
</details>
</div>
<div class="card">
<div class="title">Applying Formal Methods Tools to an Electronic Warfare Codebase (Experience report)</div>
<div class="meta-line">Authors: Letitia W. Li, Denley Lam, Vu Le, Daniel Mitchell, Mark J. Gerken, Robert B. Ross</div>
<div class="meta-line">First: 2026-01-16T18:46:19+00:00 · Latest: 2026-01-16T18:46:19+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11510v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11510v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While using formal methods offers advantages over unit testing, their steep learning curve can be daunting to developers and can be a major impediment to widespread adoption. To support integration into an industrial software engineering workflow, a tool must provide useful information and must be usable with relatively minimal user effort. In this paper, we discuss our experiences associated with identifying and applying formal methods tools on an electronic warfare (EW) system with stringent safety requirements and present perspectives on formal methods tools from EW software engineers who are proficient in development yet lack formal methods training. In addition to a difference in mindset between formal methods and unit testing approaches, some formal methods tools use terminology or annotations that differ from their target programming language, creating another barrier to adoption. Input/output contracts, objects in memory affected by a function, and loop invariants can be difficult to grasp and use. In addition to usability, our findings include a comparison of vulnerabilities detected by different tools. Finally, we present suggestions for improving formal methods usability including better documentation of capabilities, decreased manual effort, and improved handling of library code.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>将形式化方法工具应用于电子战代码库（经验报告）</div>
<div class="mono" style="margin-top:8px">尽管使用形式化方法相较于单元测试具有优势，但其陡峭的学习曲线对开发者来说可能令人望而却步，并成为广泛采用的主要障碍。为了支持形式化方法工具在工业软件工程流程中的集成，工具必须提供有用的信息，并且开发者在使用时应尽量减少手动操作。本文讨论了我们在一个具有严格安全要求的电子战（EW）系统中识别和应用形式化方法工具的经验，并从具备开发能力但缺乏形式化方法培训的EW软件工程师的角度提供了对形式化方法工具的看法。除了形式化方法与单元测试方法在思维方式上的差异外，一些形式化方法工具使用的术语或注释与目标编程语言不同，这也成为采用的另一障碍。输入/输出契约、函数影响的内存对象以及循环不变式等概念可能难以理解和应用。除了可用性问题，我们的研究结果还包括不同工具检测到的漏洞对比。最后，我们提出了改善形式化方法可用性的建议，包括更好地说明工具功能、减少手动操作以及改进对库代码的处理。</div>
</details>
</div>
<div class="card">
<div class="title">From Aggregation to Selection: User-Validated Distributed Social Recommendation</div>
<div class="meta-line">Authors: Jingyuan Huang, Dan Luo, Zihe Ye, Weixin Chen, Minghao Guo, Yongfeng Zhang</div>
<div class="meta-line">Venue: WWW 2026</div>
<div class="meta-line">First: 2025-05-27T16:17:06+00:00 · Latest: 2026-01-16T18:45:34+00:00</div>
<div class="meta-line">Comments: Accepted by HCRS@WWW 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.21388v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.21388v3">PDF</a> · <a href="https://github.com/agiresearch/DeSocial">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Social recommender systems facilitate social connections by identifying potential friends for users. Each user maintains a local social network centered around themselves, resulting in a naturally distributed social structure. Recent research on distributed modeling for social recommender systems has gained increasing attention, as it naturally aligns with the user-centric structure of user interactions. Current distributed social recommender systems rely on automatically combining predictions from multiple models, often overlooking the user&#x27;s active role in validating whether suggested connections are appropriate. Moreover, recommendation decisions are validated by individual users rather than derived from a single global ordering of candidates. As a result, standard ranking-based evaluation metrics make it difficult to evaluate whether a user-confirmed recommendation decision is actually correct. To address these limitations, we propose DeSocial, a distributed social recommendation framework with user-validation. DeSocial enables users to select recommendation algorithms to validate their potential connections, and the verification is processed through majority consensus among multiple independent user validators. To evaluate the distributed recommender system with user validator, we formulate this setting as a link prediction and verification task and introduce Acc@K, a consensus-based evaluation metric that measures whether user-approved recommendations are correct. Experiments on 4 real-world social networks shows that DeSocial improves decision correctness and robustness compared to single-point and distributed baselines. These findings highlight the potential of user-validated distributed recommender systems as a practical approach to social recommendation, with broader applicability to distributed and decentralized recommendations. Code: https://github.com/agiresearch/DeSocial.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从聚合到选择：用户验证的分布式社交推荐</div>
<div class="mono" style="margin-top:8px">社交推荐系统通过识别用户潜在的朋友来促进社交连接。每个用户维护一个以自己为中心的本地社交网络，从而形成一种自然的分布式社交结构。近年来，针对社交推荐系统的分布式建模研究日益受到关注，因为它自然地与用户交互的以用户为中心的结构相契合。当前的分布式社交推荐系统依赖于自动组合多个模型的预测结果，常常忽略了用户在验证建议连接是否合适中的主动作用。此外，推荐决策是通过个体用户验证，而不是基于候选列表的单一全局排序。因此，标准的基于排序的评估指标难以判断用户确认的推荐决策是否正确。为了解决这些局限性，我们提出了DeSocial，一个具有用户验证的分布式社交推荐框架。DeSocial允许用户选择推荐算法来验证其潜在连接，并通过多个独立用户验证者的多数共识进行验证。为了评估带有用户验证器的分布式推荐系统，我们将该设置建模为链接预测与验证任务，并引入Acc@K，一种基于共识的评估指标，用于衡量用户批准的推荐是否正确。在4个真实社交网络上的实验表明，与单点和分布式基线相比，DeSocial在决策正确性和鲁棒性方面均有提升。这些发现突显了用户验证的分布式推荐系统作为社交推荐的实用方法的潜力，并展示了其在分布式和去中心化推荐中的更广泛适用性。代码：https://github.com/agiresearch/DeSocial</div>
</details>
</div>
<div class="card">
<div class="title">ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes</div>
<div class="meta-line">Authors: Emily Steiner, Jianhao Zheng, Henry Howard-Jenkins, Chris Xie, Iro Armeni</div>
<div class="meta-line">First: 2026-01-16T18:45:19+00:00 · Latest: 2026-01-16T18:45:19+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11508v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11508v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ReScene4D：对演进室内三维场景的时序一致语义实例分割</div>
<div class="mono" style="margin-top:8px">室内环境会随着物体的移动、出现或消失而演变。捕捉这些动态变化需要在间歇性采集的三维扫描中保持时序一致的实例身份，即使在未观察到变化时也是如此。我们引入并形式化了时序稀疏的4D室内语义实例分割（SIS）任务，该任务联合分割、识别和时序关联物体实例。这种设置对现有的3D SIS方法提出了挑战，因为它们由于缺乏时序推理而需要离散的匹配步骤，同时也对4D激光雷达方法提出了挑战，因为它们依赖于高频时序测量，而这种测量在室内环境的长期演变中并不常见。我们提出了ReScene4D，一种新颖的方法，它无需密集观测即可将3D SIS架构适应到4D SIS中。该方法探索了在观测之间共享信息的策略，证明了这种共享上下文不仅能够实现一致的实例跟踪，还能提升标准3D SIS的质量。为了评估这一任务，我们定义了一个新的度量指标t-mAP，它扩展了mAP，以奖励时序身份的一致性。ReScene4D在3RScan数据集上实现了最先进的性能，为理解演进的室内场景建立了新的基准。</div>
</details>
</div>
<div class="card">
<div class="title">MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management</div>
<div class="meta-line">Authors: Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston</div>
<div class="meta-line">First: 2026-01-16T18:38:33+00:00 · Latest: 2026-01-16T18:38:33+00:00</div>
<div class="meta-line">Comments: 22 pages, 5 figures, 7 supplementary figures, submitted to JDST</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11505v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11505v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MetaboNet：目前最大的可用于1型糖尿病管理的整合公开数据集</div>
<div class="mono" style="margin-top:8px">现有1型糖尿病（T1D）管理数据集的碎片化和缺乏标准化限制了T1D算法开发的进展。当前数据集在结构上差异显著，且访问和处理过程耗时，这阻碍了数据整合并降低了算法发展的可比性和普适性。本研究旨在建立一个统一且可访问的数据资源，用于T1D算法开发。多个公开的T1D数据集被整合为一个统一资源，称为MetaboNet数据集。纳入标准要求同时具备连续血糖监测（CGM）数据和相应的胰岛素泵给药记录。此外，当存在时，保留了诸如报告的碳水化合物摄入量和体力活动等辅助信息。MetaboNet数据集包含3135名受试者和1228个患者年份的重叠CGM和胰岛素数据，使其显著大于现有的独立基准数据集。该资源以完全公开的子集形式发布，可立即从https://metabo-net.org/ 下载，同时还有一个受数据使用协议（DUA）限制的子集，需通过各自的应用流程访问。对于后者子集中的数据集，提供了处理流程以自动将数据转换为标准化的MetaboNet格式。本文呈现了一个整合的公开数据集，描述了其无限制和受DUA管理部分的访问途径。最终的数据集涵盖了广泛的血糖谱和人口统计学特征，因此可以产生比单个数据集更普适的算法性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets.</div>
</details>
</div>
<div class="card">
<div class="title">Raman scattering fingerprints of the charge density wave state in one-dimensional NbTe$_4$</div>
<div class="meta-line">Authors: Natalia Zawadzka, Cem Sevik, Zahir Muhammad, Zia Ur Rehman, Weisheng Zhao, Adam Babiński, Maciej R. Molas</div>
<div class="meta-line">First: 2026-01-16T18:33:52+00:00 · Latest: 2026-01-16T18:33:52+00:00</div>
<div class="meta-line">Comments: 7 pages, 4 figures + SM</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11502v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11502v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Charge-density waves (CDWs) are ordered quantum states of conduction electrons accompanied by periodic lattice distortions. Raman scattering (RS) spectroscopy is therefore well suited for probing CDW-induced structural modulations. We investigate the CDW state in quasi-one-dimensional NbTe$_4$ using RS spectroscopy. At $T$=5~K, the resonantly enhanced Raman spectrum exhibits 25 phonon modes. Polarization-dependent measurements reveal a strong coupling between phonon-mode symmetry and crystallographic symmetry, with modes polarized parallel or perpendicular to the crystallographic $c$-axis, along which the one-dimensional structure is elongated. Temperature-dependent RS measurements identify a transition between commensurate and incommensurate CDW phases, accompanied by pronounced thermal hysteresis, with transition temperatures of approximately 45~K upon cooling and 90~K upon warming. The hysteresis width depends on the warming rate, indicating a finite nucleation rate of CDW domains and suggesting potential relevance for memory-device applications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一维NbTe$_4$中电荷密度波态的拉曼散射指纹</div>
<div class="mono" style="margin-top:8px">电荷密度波（CDW）是导电电子的有序量子态，伴随着周期性的晶格畸变。因此，拉曼散射（RS）光谱非常适合探测CDW引起的结构调制。我们利用RS光谱研究准一维NbTe$_4$中的CDW态。在$T$=5~K时，共振增强的拉曼光谱显示出25个声子模式。偏振依赖的测量揭示了声子模式对称性与晶体对称性之间的强耦合关系，其中沿晶体$ c $轴（一维结构延伸方向）平行或垂直偏振的模式表现出显著差异。温度依赖的RS测量识别出从可调谐到不可调谐CDW相的转变，伴随着明显的热滞后现象，冷却时转变温度约为45~K，升温时约为90~K。滞后宽度依赖于升温速率，表明CDW畴的有限成核速率，并暗示其在记忆器件应用中的潜在相关性。</div>
</details>
</div>
<div class="card">
<div class="title">Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them</div>
<div class="meta-line">Authors: Jiahe Jin, Abhijay Paladugu, Chenyan Xiong</div>
<div class="meta-line">First: 2025-10-08T00:20:35+00:00 · Latest: 2026-01-16T18:30:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.06534v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.06534v3">PDF</a> · <a href="https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic search requires large language models (LLMs) to perform multi-step search to solve complex information-seeking tasks, imposing unique challenges on their reasoning capabilities. However, what constitutes effective reasoning for agentic search and how it can be learned remains unclear. In this work, we first investigate the reasoning behaviors that enable success in agentic search. By comparing successful and failed trajectories via an LLM-based analysis pipeline, we identify four beneficial behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. Building on this, we propose Behavior Priming, a training approach that equips agentic search models with these reasoning behaviors before reinforcement learning (RL). Specifically, it first performs supervised fine-tuning (SFT) on collected trajectories exhibiting the identified behaviors to cultivate these behaviors, and then applies standard RL to further improve task performance. Experiments on Qwen3-1.7B and Llama3.2-3B-Instruct show that Behavior Priming yields relative improvements over direct RL by 37.2\% on three web benchmarks and 6.2\% on seven multi-hop QA benchmarks, and outperforms the SFT-then-RL baseline using outcome-correct trajectories for fine-tuning. Crucially, we show that these reasoning behaviors matter more than outcome correctness in the priming stage prior to RL. Further analysis reveals that Behavior Priming enhances exploration (pass@8) and test-time scaling (search step number), providing a robust foundation for RL. Our code are avalible at https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>代理搜索中的有益推理行为与获取它们的有效后训练</div>
<div class="mono" style="margin-top:8px">代理搜索要求大语言模型（LLMs）执行多步骤搜索以解决复杂的任务，这对它们的推理能力提出了独特的挑战。然而，什么构成代理搜索中的有效推理以及如何学习这些推理行为仍不清楚。在本工作中，我们首先研究了使代理搜索成功所需的推理行为。通过基于LLM的分析流程比较成功与失败的轨迹，我们识别出四种有益行为：信息验证、权威评估、自适应搜索和错误恢复。在此基础上，我们提出了行为引导（Behavior Priming），这是一种在强化学习（RL）之前为代理搜索模型赋予这些推理行为的训练方法。具体而言，它首先在展示这些行为的轨迹上进行监督微调（SFT），以培养这些行为，然后应用标准RL进一步提升任务性能。在Qwen3-1.7B和Llama3.2-3B-Instruct上的实验表明，行为引导在三个网络基准测试中相对于直接RL提升了37.2%，在七个多跳问答基准测试中提升了6.2%。此外，使用结果正确的轨迹进行微调，行为引导优于SFT-然后-RL的基线。关键的是，我们证明了在强化学习之前的引导阶段，这些推理行为比结果正确性更为重要。进一步分析表明，行为引导增强了探索能力（pass@8）和测试时的扩展性（搜索步骤数量），为强化学习提供了坚实的基础。我们的代码可在https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search获取。</div>
</details>
</div>
<div class="card">
<div class="title">QUPID: A Partitioned Quantum Neural Network for Anomaly Detection in Smart Grid</div>
<div class="meta-line">Authors: Hoang M. Ngo, Tre&#x27; R. Jeter, Jung Taek Seo, My T. Thai</div>
<div class="meta-line">First: 2026-01-16T18:30:24+00:00 · Latest: 2026-01-16T18:30:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11500v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11500v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Smart grid infrastructures have revolutionized energy distribution, but their day-to-day operations require robust anomaly detection methods to counter risks associated with cyber-physical threats and system faults potentially caused by natural disasters, equipment malfunctions, and cyber attacks. Conventional machine learning (ML) models are effective in several domains, yet they struggle to represent the complexities observed in smart grid systems. Furthermore, traditional ML models are highly susceptible to adversarial manipulations, making them increasingly unreliable for real-world deployment. Quantum ML (QML) provides a unique advantage, utilizing quantum-enhanced feature representations to model the intricacies of the high-dimensional nature of smart grid systems while demonstrating greater resilience to adversarial manipulation. In this work, we propose QUPID, a partitioned quantum neural network (PQNN) that outperforms traditional state-of-the-art ML models in anomaly detection. We extend our model to R-QUPID that even maintains its performance when including differential privacy (DP) for enhanced robustness. Moreover, our partitioning framework addresses a significant scalability problem in QML by efficiently distributing computational workloads, making quantum-enhanced anomaly detection practical in large-scale smart grid environments. Our experimental results across various scenarios exemplifies the efficacy of QUPID and R-QUPID to significantly improve anomaly detection capabilities and robustness compared to traditional ML approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>QUPID：一种用于智能电网异常检测的分区量子神经网络</div>
<div class="mono" style="margin-top:8px">智能电网基础设施革新了能源分配方式，但其日常运行需要强大的异常检测方法以应对与网络物理威胁和系统故障相关的风险，这些故障可能由自然灾害、设备故障和网络攻击引起。传统机器学习（ML）模型在多个领域表现出色，但在表示智能电网系统中观察到的复杂性方面存在困难。此外，传统ML模型极易受到对抗性操控的影响，使其在现实部署中日益不可靠。量子机器学习（QML）提供了一种独特优势，利用量子增强的特征表示来建模智能电网系统的高维特性，同时表现出更强的对抗性鲁棒性。在本工作中，我们提出了QUPID，一种分区量子神经网络（PQNN），在异常检测方面优于传统最先进的ML模型。我们进一步扩展了该模型为R-QUPID，即使在引入差分隐私（DP）以增强鲁棒性的情况下，也能保持其性能。此外，我们的分区框架通过高效分配计算负载，解决了QML中的一个重要可扩展性问题，使量子增强的异常检测在大规模智能电网环境中具备实际应用价值。我们的实验结果在各种场景中展示了QUPID和R-QUPID在显著提升异常检测能力和鲁棒性方面相较于传统ML方法的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Conditional Distribution Compression via the Kernel Conditional Mean Embedding</div>
<div class="meta-line">Authors: Dominic Broadbent, Nick Whiteley, Robert Allison, Tom Lovett</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-04-14T11:53:29+00:00 · Latest: 2026-01-16T18:26:41+00:00</div>
<div class="meta-line">Comments: 76 pages, 32 figures, accepted into NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.10139v4">Abs</a> · <a href="https://arxiv.org/pdf/2504.10139v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing distribution compression methods, like Kernel Herding (KH), were originally developed for unlabelled data. However, no existing approach directly compresses the conditional distribution of \textit{labelled} data. To address this gap, we first introduce the Average Maximum Conditional Mean Discrepancy (AMCMD), a metric for comparing conditional distributions, and derive a closed form estimator. Next, we make a key observation: in the context of distribution compression, the cost of constructing a compressed set targeting the AMCMD can be reduced from cubic to linear. Leveraging this, we extend KH to propose Average Conditional Kernel Herding (ACKH), a linear-time greedy algorithm for constructing compressed sets that target the AMCMD. To better understand the advantages of directly compressing the conditional distribution rather than doing so via the joint distribution, we introduce Joint Kernel Herding (JKH), an adaptation of KH designed to compress the joint distribution of labelled data. While herding methods provide a simple and interpretable selection process, they rely on a greedy heuristic. To explore alternative optimisation strategies, we also propose Joint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing Points (ACKIP), which jointly optimise the compressed set while maintaining linear complexity. Experiments show that directly preserving conditional distributions with ACKIP outperforms both joint distribution compression and the greedy selection used in ACKH. Moreover, we see that JKIP consistently outperforms JKH.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过核条件均值嵌入进行条件分布压缩</div>
<div class="mono" style="margin-top:8px">现有的分布压缩方法，如核采样（Kernel Herding, KH），最初是为无标签数据设计的。然而，目前尚无直接压缩标签数据条件分布的方法。为了解决这一问题，我们首先引入平均最大条件均值差异（Average Maximum Conditional Mean Discrepancy, AMCMD），这是一种用于比较条件分布的度量，并推导出其闭式估计器。接着，我们做出一个关键观察：在分布压缩的背景下，针对AMCMD构建压缩集的成本可以从立方复杂度降低到线性复杂度。利用这一特性，我们将KH扩展为平均条件核采样（Average Conditional Kernel Herding, ACKH），这是一种针对AMCMD构建压缩集的线性时间贪心算法。为了更好地理解直接压缩条件分布相较于通过联合分布进行压缩的优势，我们引入了联合核采样（Joint Kernel Herding, JKH），这是KH的一种变体，旨在压缩标签数据的联合分布。虽然采样方法提供了一种简单且可解释的选择过程，但它们依赖于贪心启发式策略。为了探索替代的优化策略，我们还提出了联合核诱导点（Joint Kernel Inducing Points, JKIP）和平均条件核诱导点（Average Conditional Kernel Inducing Points, ACKIP），它们在保持线性复杂度的同时联合优化压缩集。实验表明，使用ACKIP直接保留条件分布的效果优于联合分布压缩和ACKH中使用的贪心选择。此外，我们还发现JKIP在性能上始终优于JKH。</div>
</details>
</div>
<div class="card">
<div class="title">Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices</div>
<div class="meta-line">Authors: Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha</div>
<div class="meta-line">First: 2026-01-05T18:55:05+00:00 · Latest: 2026-01-16T18:26:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.02353v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.02353v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A key challenge in agricultural AI is deploying disease detection systems in remote fields with limited access to laboratories or high-performance computing (HPC) resources. While deep learning (DL) models, specifically deep convolutional networks, achieve high accuracy in identifying plant pathologies from leaf imagery, their memory footprints and computational demands limit edge deployment on devices constrained by battery life, processing power, and connectivity, such as Raspberry Pi. Few-shot learning (FSL) paradigms offer a compelling solution to the data scarcity problem inherent in agricultural applications, where obtaining labeled samples for novel disease variants proves both costly and time-sensitive. This work introduces a framework combining pruning with meta-learning for agricultural disease classification, addressing the tension between generalization capability and deployment feasibility. The proposed approach combines a novel Disease-Aware Channel Importance Scoring (DACIS) mechanism with a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy. The compressed model achieves 7 frames per second (FPS) on a Raspberry Pi 4, enabling practical real-time field diagnosis for smallholder farmers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于元学习引导的边缘设备少样本植物病理学检测剪枝方法</div>
<div class="mono" style="margin-top:8px">农业人工智能中的一个关键挑战是在缺乏实验室或高性能计算（HPC）资源的偏远田间部署疾病检测系统。尽管深度学习（DL）模型，特别是深度卷积网络，在从叶片图像识别植物病害方面取得了高精度，但其内存占用和计算需求限制了在电池寿命、处理能力和连接性受限的设备（如Raspberry Pi）上的边缘部署。少样本学习（FSL）范式为农业应用中固有的数据稀缺问题提供了一个有吸引力的解决方案，因为在获取新型病害变种的标注样本方面既昂贵又耗时。本文提出了一种结合剪枝与元学习的框架，用于农业病害分类，解决了泛化能力与部署可行性之间的矛盾。所提出的方法结合了一种新颖的疾病感知通道重要性评分（DACIS）机制与三阶段剪枝-元学习-再剪枝（PMP）流程。在PlantVillage和PlantDoc数据集上的实验表明，该方法在保持原准确率的92.3%的同时，将模型大小减少了78%。压缩后的模型在Raspberry Pi 4上实现了每秒7帧（FPS）的推理速度，使小农户能够在田间进行实用的实时诊断。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A key challenge in agricultural AI is deploying disease detection systems in remote fields with limited access to laboratories or high-performance computing (HPC) resources.</div>
</details>
</div>
<div class="card">
<div class="title">On the Probability of First Success in Differential Evolution: Hazard Identities and Tail Bounds</div>
<div class="meta-line">Authors: Dimitar Nedanovski, Svetoslav Nenov, Dimitar Pilev</div>
<div class="meta-line">First: 2026-01-16T18:24:24+00:00 · Latest: 2026-01-16T18:24:24+00:00</div>
<div class="meta-line">Comments: All codes are publically available at https://github.com/snenovgmailcom/lshade_hazard_project</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11499v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11499v1">PDF</a> · <a href="https://github.com/snenovgmailcom/lshade_hazard_project">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\Prob(E_t\mid\mathcal F_{t-1})$. This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event.
  For the L-SHADE algorithm with current-to-$p$best/1 mutation, we construct a checkable algorithmic witness event $\mathcal L_t$ under which the conditional hazard admits an explicit lower bound depending only on sampling rules, population size, and crossover statistics. This separates theoretical constants from empirical event frequencies and explains why worst-case constant-hazard bounds are typically conservative.
  We complement the theory with a Kaplan--Meier survival analysis on the CEC2017 benchmark suite . Across functions and budgets, we identify three distinct empirical regimes: (i) strongly clustered success, where hitting times concentrate in short bursts; (ii) approximately geometric tails, where a constant-hazard model is accurate; and (iii) intractable cases with no observed hits within the evaluation horizon. The results show that while constant-hazard bounds provide valid tail envelopes, the practical behavior of L-SHADE is governed by burst-like transitions rather than homogeneous per-generati on success probabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>差分进化中首次成功概率的分析：风险身份与尾界</div>
<div class="mono" style="margin-top:8px">我们通过条件风险框架研究差分进化（DE）中的首次命中时间。我们不通过马尔可夫链转移核或漂移论证来分析收敛性，而是将可测目标集 $A$ 的生存概率表示为条件首次命中概率（风险）$p_t=\Prob(E_t\mid\mathcal F_{t-1})$ 的乘积。这在风险具有确定性下界时，提供了无分布依赖的生存身份和显式的尾界。
对于采用当前到 $p$ 最优解/1 变异策略的 L-SHADE 算法，我们构建了一个可验证的算法见证事件 $\mathcal L_t$，在该事件下，条件风险可以显式地表示为仅依赖于采样规则、种群规模和交叉统计量的下界。这将理论常数与经验事件频率分离，并解释了为什么最坏情况下的常数风险界通常过于保守。
我们通过 Kaplan--Meier 生存分析补充理论，对 CEC2017 基准集进行研究。在不同函数和预算下，我们识别出三种不同的经验模式：(i) 强烈聚集的成功，其中命中时间集中在短时间爆发中；(ii) 近似几何尾部，其中常数风险模型是准确的；以及 (iii) 无法处理的情况，其中在评估范围内未观察到任何命中。结果表明，尽管常数风险界提供了有效的尾部包络，但 L-SHADE 的实际行为由类似爆发的转移过程主导，而非每一代均等的成功概率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work.</div>
</details>
</div>
<div class="card">
<div class="title">A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints</div>
<div class="meta-line">Authors: Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy</div>
<div class="meta-line">First: 2025-07-17T10:31:31+00:00 · Latest: 2026-01-16T18:20:30+00:00</div>
<div class="meta-line">Comments: Accepted and published in Transactions on Machine Learning Research (TMLR), 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.12979v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.12979v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://distributed-gen-ai.github.io/huscf-gan.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning has gained attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables utilizing distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experiments show that our approach demonstrates significant improvements across key metrics, where it achieves an average 10% boost in classification metrics (up to 60% in multi-domain non-IID settings), 1.1x -- 3x higher image generation scores for the MNIST family datasets, and 2x -- 70x lower FID scores for higher resolution datasets. Find our code at https://distributed-gen-ai.github.io/huscf-gan.github.io/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种在数据共享约束下的异构多领域环境中的分布式生成式人工智能方法</div>
<div class="mono" style="margin-top:8px">联邦学习因其能够在不共享原始数据的情况下使多个节点协同训练机器学习模型而受到关注。同时，生成式人工智能——特别是生成对抗网络（GANs）——在医疗、安全和图像生成等多个领域取得了显著成功。然而，训练生成模型通常需要大规模数据集和大量计算资源，这些资源在现实场景中往往难以获得。获取这些资源可能成本高昂且效率低下，尤其是在许多未充分利用的设备（如物联网设备和边缘设备）仍处于闲置状态的情况下。此外，由于隐私问题和版权限制，获取大规模数据集具有挑战性，因为大多数设备都不愿意共享其数据。为了解决这些挑战，我们提出了一种新颖的去中心化GAN训练方法，能够在不共享原始数据的情况下利用分布式数据和低能力的闲置设备。我们的方法旨在应对去中心化环境中的关键挑战，结合KLD加权聚类联邦学习以解决数据异构性和多领域数据集的问题，并采用异构U型分割学习来应对严格数据共享约束下的设备异构性问题——确保节点之间从不共享任何标签或原始数据（无论是真实还是合成的）。实验表明，我们的方法在关键指标上实现了显著提升，在分类指标上平均提高了10%（在多领域非独立同分布设置中最高可达60%），在MNIST家族数据集上的图像生成得分提高了1.1到3倍，而在更高分辨率数据集上的FID得分则降低了2到70倍。</div>
</details>
</div>
<div class="card">
<div class="title">The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</div>
<div class="meta-line">Authors: Eilam Shapira, Roi Reichart, Moshe Tennenholtz</div>
<div class="meta-line">First: 2026-01-16T18:18:03+00:00 · Latest: 2026-01-16T18:18:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11496v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11496v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the &quot;Poisoned Apple&quot; effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator&#x27;s choice of market design in their favor. This strategic release improves the releaser&#x27;s welfare at the expense of their opponent and the regulator&#x27;s fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>毒苹果效应：通过AI代理技术扩展对中介市场的战略操控</div>
<div class="mono" style="margin-top:8px">人工智能代理的引入从根本上改变了经济市场中的战略互动格局。我们研究了在三种经典的博弈论场景下，扩展可用技术集的经济影响：谈判（资源分配）、协商（不对称信息交易）和说服（战略信息传递）。我们发现，仅仅增加AI代理的选择范围就可以显著改变均衡收益和监管结果，常常促使监管者主动开发和发布技术。相反，我们识别出一种战略现象，称为“毒苹果”效应：一个代理可能发布一项新技术，但最终既不自己使用，也不被对手使用，仅仅是为了操控监管者在市场设计上的选择以谋取自身利益。这种战略行为提升了发布者的福利，却损害了对手和监管者的公平目标。我们的研究结果表明，静态的监管框架容易受到技术扩展的操控，因此需要动态的市场设计来适应AI能力的不断演进。</div>
</details>
</div>
<div class="card">
<div class="title">Differentiable Cyclic Causal Discovery Under Unmeasured Confounders</div>
<div class="meta-line">Authors: Muralikrishnna G. Sethuraman, Faramarz Fekri</div>
<div class="meta-line">First: 2025-08-11T20:13:34+00:00 · Latest: 2026-01-16T18:16:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.08450v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.08450v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding causal relationships between variables is fundamental across scientific disciplines. Most causal discovery algorithms rely on two key assumptions: (i) all variables are observed, and (ii) the underlying causal graph is acyclic. While these assumptions simplify theoretical analysis, they are often violated in real-world systems, such as biological networks. Existing methods that account for confounders either assume linearity or struggle with scalability. To address these limitations, we propose DCCD-CONF, a novel framework for differentiable learning of nonlinear cyclic causal graphs in the presence of unmeasured confounders using interventional data. Our approach alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the log-likelihood of the data. Through experiments on synthetic data and real-world gene perturbation datasets, we show that DCCD-CONF outperforms state-of-the-art methods in both causal graph recovery and confounder identification. Additionally, we also provide consistency guarantees for our framework, reinforcing its theoretical soundness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在未测量混杂因素下的可微分循环因果发现</div>
<div class="mono" style="margin-top:8px">理解变量之间的因果关系是科学各学科的基础。大多数因果发现算法依赖两个关键假设：(i) 所有变量都是可观测的，(ii) 基础因果图是无环的。虽然这些假设简化了理论分析，但在现实系统中（如生物网络）往往被违反。现有的考虑混杂因素的方法要么假设线性，要么在可扩展性方面存在困难。为了解决这些限制，我们提出了一种新的框架 DCCD-CONF，用于在存在未测量混杂因素的情况下，利用干预数据进行非线性循环因果图的可微分学习。我们的方法通过最大化数据的对数似然，在优化因果图结构和估计混杂因素分布之间交替进行。通过在合成数据和真实世界基因扰动数据集上的实验，我们展示了 DCCD-CONF 在因果图恢复和混杂因素识别方面均优于现有最先进的方法。此外，我们还为该框架提供了相容性保证，加强了其理论可靠性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Understanding causal relationships between variables is fundamental across scientific disciplines.</div>
</details>
</div>
<div class="card">
<div class="title">BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics</div>
<div class="meta-line">Authors: Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu</div>
<div class="meta-line">First: 2026-01-16T18:14:46+00:00 · Latest: 2026-01-16T18:14:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11492v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11492v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team&#x27;s historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BoxMind：在2024年奥运会中验证的精英拳击闭环AI策略优化</div>
<div class="mono" style="margin-top:8px">竞技体育需要复杂的战术分析，但像拳击这样的对抗性运动在AI驱动的分析中仍处于发展初期，这主要归因于动作动态的复杂性和缺乏结构化的战术表示。为了解决这一问题，我们提出了BoxMind，一个在精英拳击比赛中验证的闭环AI专家系统。通过定义具有精确时间边界和空间与技术属性的原子击打事件，我们将比赛录像解析为18个分层的技术战术指标。随后，我们提出了一种基于图的预测模型，将这些显式的战术技术特征与可学习的时间变化潜在嵌入融合，以捕捉拳手之间的对抗动态。我们将比赛结果建模为技术战术指标的可微函数，从而将获胜概率梯度转化为可执行的战术调整。实验表明，该结果预测模型在BoxerGraph测试集上达到69.8%的准确率，在奥运会比赛中达到87.5%。基于此预测模型，系统生成的策略建议展现出与人类专家相当的专业水平。BoxMind在2024年巴黎奥运会的闭环部署中得到验证，直接助力中国国家队取得历史性三金两银的佳绩。BoxMind建立了一个可复制的范式，将非结构化的视频数据转化为战略智能，弥合了计算机视觉与竞技体育决策支持之间的差距。</div>
</details>
</div>
<div class="card">
<div class="title">Extractive summarization on a CMOS Ising machine</div>
<div class="meta-line">Authors: Ziqing Zeng, Abhimanyu Kumar, Chris H. Kim, Ulya R. Karpuzcu, Sachin S. Sapatnekar</div>
<div class="meta-line">First: 2026-01-16T18:14:02+00:00 · Latest: 2026-01-16T18:14:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11491v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11491v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于CMOS耦合振荡器的Ising机上的抽取式摘要</div>
<div class="mono" style="margin-top:8px">抽取式摘要（ES）旨在通过从文档中选择一组句子生成简洁摘要，同时最大化相关性并最小化冗余。尽管现代ES系统使用强大的神经模型实现了高精度，但其部署通常依赖于能耗高且不适合资源受限环境中实时推理的CPU或GPU基础设施。在本工作中，我们探讨了在低功耗CMOS耦合振荡器基Ising机（COBI）上实现McDonald式抽取式摘要的可行性，该机器支持整数值的全连接自旋耦合。我们首先提出了一种面向硬件的Ising公式化方法，以减少局部场与耦合项之间的规模失衡，从而提高对系数量化误差的鲁棒性：该方法可应用于任何需要从n个变量中选择k个变量的问题公式化。随后，我们开发了一个完整的ES流程，包括（i）随机舍入和迭代优化以补偿精度损失，以及（ii）一种分解策略，将大规模的ES问题分解为多个可高效求解的Ising子问题，之后再将这些子问题结果合并。在CNN/DailyMail数据集上的实验结果表明，我们的流程仅使用有限精度的整数耦合Ising硬件即可生成高质量摘要。与暴力搜索方法相比，COBI实现了3-4.5倍的运行时间加速，与软件Tabu搜索相当，同时在能耗方面减少了两个到三个数量级，同时保持了具有竞争力的摘要质量。这些结果突显了在边缘设备上部署CMOS Ising求解器用于实时、低能耗文本摘要的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation</div>
<div class="meta-line">Authors: Vanshali Sharma, Andrea Mia Bejar, Gorkem Durak, Ulas Bagci</div>
<div class="meta-line">Venue: ISBI 2026</div>
<div class="meta-line">First: 2026-01-16T18:09:19+00:00 · Latest: 2026-01-16T18:09:19+00:00</div>
<div class="meta-line">Comments: Accepted at ISBI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11488v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11488v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts. To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG. The modules test: (i) Writing Style Generalizability (WSG) via LLM-based rephrasing; (ii) Synthetic Error Injection (SEI) at graded severities; and (iii) Metrics-vs-Expert correlation (MvE) using clinician ratings on 175 &quot;disagreement&quot; cases. Eight widely used metrics (BLEU, ROUGE, METEOR, BERTScore-F1, F1-RadGraph, RaTEScore, GREEN Score, CRG) are studied across seven LLMs built on a CT-CLIP encoder. Using our novel framework, we found that lexical NLG metrics are highly sensitive to stylistic variations; GREEN Score aligns best with expert judgments (Spearman~0.70), while CRG shows negative correlation; and BERTScore-F1 is least sensitive to factual error injection. We will release the framework, code, and allowable portion of the anonymized evaluation data (rephrased/error-injected CT reports), to facilitate reproducible benchmarking and future metric development.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CTest-Metric：一种用于CT报告生成临床有效性的统一评估框架</div>
<div class="mono" style="margin-top:8px">在生成式人工智能时代，即使关键的医疗任务也日益自动化，放射学报告生成（RRG）仍依赖于次优的评估指标。因此，开发领域特定的评估指标成为研究的热点，但由于缺乏统一且明确的框架来评估其在临床环境中的稳健性和适用性，这仍然是一个具有挑战性的问题。为了解决这一问题，我们提出了CTest-Metric，这是首个统一的指标评估框架，包含三个模块，用于评估CT RRG指标的临床可行性。这三个模块分别测试：(i) 基于大语言模型（LLM）的重述来评估写作风格的泛化能力（WSG）；(ii) 在不同严重程度下进行合成错误注入（SEI）；以及 (iii) 指标与专家判断的相关性（MvE），使用临床医生对175个“分歧”案例的评分。我们在基于CT-CLIP编码器的七种大语言模型上研究了八种广泛使用的指标（BLEU、ROUGE、METEOR、BERTScore-F1、F1-RadGraph、RaTEScore、GREEN Score、CRG）。通过我们提出的新型框架，我们发现词汇层面的自然语言生成（NLG）指标对风格变化非常敏感；GREEN Score与专家判断最为一致（斯皮尔曼相关系数约0.70），而CRG则表现出负相关；BERTScore-F1对事实错误的注入最不敏感。我们将发布该框架、代码以及匿名化评估数据中允许使用的部分（重述/错误注入的CT报告），以促进可复现的基准测试和未来指标的发展。</div>
</details>
</div>
<div class="card">
<div class="title">Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training</div>
<div class="meta-line">Authors: Shuo Cheng, Liqian Ma, Zhenyang Chen, Ajay Mandlekar, Caelan Garrett, Danfei Xu</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-09-23T04:32:53+00:00 · Latest: 2026-01-16T18:05:09+00:00</div>
<div class="meta-line">Comments: Accepted to NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18631v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.18631v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://ot-sim2real.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Behavior cloning has shown promise for robot manipulation, but real-world demonstrations are costly to acquire at scale. While simulated data offers a scalable alternative, particularly with advances in automated demonstration generation, transferring policies to the real world is hampered by various simulation and real domain gaps. In this work, we propose a unified sim-and-real co-training framework for learning generalizable manipulation policies that primarily leverages simulation and only requires a few real-world demonstrations. Central to our approach is learning a domain-invariant, task-relevant feature space. Our key insight is that aligning the joint distributions of observations and their corresponding actions across domains provides a richer signal than aligning observations (marginals) alone. We achieve this by embedding an Optimal Transport (OT)-inspired loss within the co-training framework, and extend this to an Unbalanced OT framework to handle the imbalance between abundant simulation data and limited real-world examples. We validate our method on challenging manipulation tasks, showing it can leverage abundant simulation data to achieve up to a 30% improvement in the real-world success rate and even generalize to scenarios seen only in simulation. Project webpage: https://ot-sim2real.github.io/.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Behavior cloning has shown promise for robot manipulation, but real-world demonstrations are costly to acquire at scale.</div>
</details>
</div>
<div class="card">
<div class="title">Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning</div>
<div class="meta-line">Authors: Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, Stéphane Verguet, Milind Tambe</div>
<div class="meta-line">First: 2026-01-16T18:02:09+00:00 · Latest: 2026-01-16T18:02:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11479v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11479v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ethiopia&#x27;s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework&#x27;s effectiveness and its potential to inform equitable, data-driven health system planning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>埃塞俄比亚卫生设施选址：利用大语言模型将专家知识整合到算法规划中</div>
<div class="mono" style="margin-top:8px">埃塞俄比亚卫生部正在升级卫生站以改善对基本服务的可及性，特别是在农村地区。然而，资源有限，需要仔细优先选择升级的设施，以在考虑多样化专家和利益相关者偏好情况下最大化人口覆盖。我们与埃塞俄比亚公共卫生研究所和卫生部合作，提出了一种混合框架，系统地将专家知识与优化技术相结合。经典优化方法提供理论保证，但需要明确的、定量的目标，而利益相关者标准通常以自然语言表达，难以形式化。为弥合这两个领域，我们开发了大语言模型与扩展贪心（LEG）框架。我们的框架结合了可证明近似算法以优化人口覆盖，并通过大语言模型驱动的迭代优化来整合人类与人工智能的对齐，确保解决方案反映专家的定性指导，同时保持覆盖保证。在三个埃塞俄比亚地区的实际数据上的实验展示了该框架的有效性及其在促进公平、数据驱动的卫生系统规划中的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">Temporal Complexity and Self-Organization in an Exponential Dense Associative Memory Model</div>
<div class="meta-line">Authors: Marco Cafiso, Paolo Paradisi</div>
<div class="meta-line">First: 2026-01-16T18:01:14+00:00 · Latest: 2026-01-16T18:01:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11478v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11478v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Dense Associative Memory (DAM) models generalize the classical Hopfield model by incorporating n-body or exponential interactions that greatly enhance storage capacity. While the criticality of DAM models has been largely investigated, mainly within a statistical equilibrium picture, little attention has been devoted to the temporal self-organizing behavior induced by learning. In this work, we investigate the behavior of a stochastic exponential DAM (SEDAM) model through the lens of Temporal Complexity (TC), a framework that characterizes complex systems by intermittent transition events between order and disorder and by scale-free temporal statistics. Transition events associated with birth-death of neural avalanche structures are exploited for the TC analyses and compared with analogous transition events based on coincidence structures. We systematically explore how TC indicators depend on control parameters, i.e., noise intensity and memory load. Our results reveal that the SEDAM model exhibits regimes of complex intermittency characterized by nontrivial temporal correlations and scale-free behavior, indicating the spontaneous emergence of self-organizing dynamics. These regimes emerge in small intervals of noise intensity values, which, in agreement with the extended criticality concept, never shrink to a single critical point. Further, the noise intensity range needed to reach the critical region, where self-organizing behavior emerges, slightly decreases as the memory load increases. This study highlights the relevance of TC as a complementary framework for understanding learning and information processing in artificial and biological neural systems, revealing the link between the memory load and the self-organizing capacity of the network.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>指数密集联想记忆模型中的时间复杂性与自组织</div>
<div class="mono" style="margin-top:8px">密集联想记忆（DAM）模型通过引入n体或指数相互作用，扩展了经典Hopfield模型，显著提高了存储容量。尽管DAM模型的临界性已被广泛研究，主要是在统计平衡框架下进行的，但对由学习引发的时间自组织行为的关注却很少。在本研究中，我们通过时间复杂性（TC）框架研究了随机指数DAM（SEDAM）模型的行为，该框架通过有序与无序之间的间歇性转变事件和无标度时间统计来表征复杂系统。我们利用与神经雪崩结构的产生和消亡相关的转变事件进行TC分析，并将其与基于巧合结构的类似转变事件进行比较。我们系统地探讨了TC指标如何依赖于控制参数，即噪声强度和记忆负载。研究结果表明，SEDAM模型表现出具有非平凡时间相关性和无标度行为的复杂间歇性区域，表明自组织动力学的自发出现。这些区域出现在噪声强度值的小范围内，这与扩展临界性概念一致，这些范围从未缩小到单一临界点。此外，达到自组织行为出现的临界区域所需的噪声强度范围，随着记忆负载的增加而略有减小。本研究突显了TC作为理解人工和生物神经系统中学习与信息处理的补充框架的相关性，揭示了记忆负载与网络自组织能力之间的联系。</div>
</details>
</div>
<div class="card">
<div class="title">Galactic core-tail structure in BEC dark matter with Kapitza potential</div>
<div class="meta-line">Authors: Itauany do Nascimento Barroso, Hermano Velten</div>
<div class="meta-line">First: 2026-01-16T18:00:23+00:00 · Latest: 2026-01-16T18:00:23+00:00</div>
<div class="meta-line">Comments: 12 pages; 16 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11477v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11477v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recently, the experimental realization of a Kapitza potential in a Bose-Einstein Condensate (BEC) has been reported for the first time in literature, motivating further theoretical investigations of such system. At the same time, in the astrophysical context, BEC dark matter models have been widely studied as a possible phenomenological explanation for the dark matter phenomena. We model the galactic structure with an inner cored profile obtained from the ground state equilibrium solution of the Schroedinger-Poisson together with a Kapitza-BEC like interaction for the tail region. We find reasonable agreement of the model with representative galaxy rotation curves available in the SPARC catalogue.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>具有Kapitza势的玻色-爱因斯坦凝聚暗物质中的银河核心-尾结构</div>
<div class="mono" style="margin-top:8px">最近，文献中首次报道了在玻色-爱因斯坦凝聚体（BEC）中实现Kapitza势的实验，这激发了对该系统的进一步理论研究。同时，在天体物理背景下，BEC暗物质模型已被广泛研究，作为解释暗物质现象的一种可能的表观模型。我们通过结合Schroedinger-Poisson方程的基态平衡解得到的核心型轮廓，以及类似Kapitza-BEC的相互作用来建模银河结构。我们发现该模型与SPARC目录中可获得的代表性星系旋转曲线存在合理的吻合。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recently, the experimental realization of a Kapitza potential in a Bose-Einstein Condensate (BEC) has been reported for the first time in literature, motivating further theoretical investigations of such system.</div>
</details>
</div>
<div class="card">
<div class="title">What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study</div>
<div class="meta-line">Authors: Xiaoran Fan, Zhichao Sun, Yangfan Gao, Jingfei Xiong, Hang Yan, Yifei Cao, Jiajun Sun, Shuo Li, Zhihao Zhang, Zhiheng Xi, Yuhao Zhou, Senjie Jin, Changhao Jiang, Junjie Ye, Ming Zhang, Rui Zheng, Zhenhua Han, Yunke Zhang, Demei Yan, Shaokang Dong, Tao Ji, Tao Gui</div>
<div class="meta-line">First: 2025-06-14T15:26:31+00:00 · Latest: 2026-01-16T17:59:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.12537v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.12537v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Speech-language models (SLMs) offer a promising path toward unifying speech and text understanding and generation. However, challenges remain in achieving effective cross-modal alignment and high-quality speech generation. In this work, we systematically investigate the role of speech tokenizer designs in LLM-centric SLMs, augmented by speech heads and speaker modeling. We compare coupled, semi-decoupled, and fully decoupled speech tokenizers under a fair SLM framework and find that decoupled tokenization significantly improves alignment and synthesis quality. To address the information density mismatch between speech and text, we introduce multi-token prediction (MTP) into SLMs, enabling each hidden state to decode multiple speech tokens. This leads to up to 12$\times$ faster decoding and a substantial drop in word error rate (from 6.07 to 3.01). Furthermore, we propose a speaker-aware generation paradigm and introduce RoleTriviaQA, a large-scale role-playing knowledge QA benchmark with diverse speaker identities. Experiments demonstrate that our methods enhance both knowledge understanding and speaker consistency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向LLM中心的语音生成，什么是好的语音分词器？一项系统性研究</div>
<div class="mono" style="margin-top:8px">语音语言模型（SLMs）为统一语音和文本的理解与生成提供了一条有前景的路径。然而，在实现有效的跨模态对齐和高质量语音生成方面仍存在挑战。在本工作中，我们系统地研究了在增强型语音头和说话人建模的LLM中心SLMs中，语音分词器设计的作用。我们在公平的SLM框架下比较了耦合、半解耦和完全解耦的语音分词器，并发现解耦分词显著提高了对齐和合成质量。为了解决语音和文本之间的信息密度不匹配问题，我们引入了多分词预测（MTP）机制，使每个隐藏状态能够解码多个语音分词。这使得解码速度提高了最多12倍，并显著降低了词错误率（从6.07降至3.01）。此外，我们提出了一种说话人感知的生成范式，并引入了RoleTriviaQA，这是一个具有多样说话人身份的大规模角色扮演知识问答基准。实验表明，我们的方法在知识理解和说话人一致性方面均有所提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Speech-language models (SLMs) offer a promising path toward unifying speech and text understanding and generation.</div>
</details>
</div>
<div class="card">
<div class="title">UCB-type Algorithm for Budget-Constrained Expert Learning</div>
<div class="meta-line">Authors: Ilgam Latypov, Alexandra Suvorikova, Alexey Kroshnin, Alexander Gasnikov, Yuriy Dorn</div>
<div class="meta-line">First: 2025-10-26T12:36:17+00:00 · Latest: 2026-01-16T17:59:33+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.22654v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.22654v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In many modern applications, a system must dynamically choose between several adaptive learning algorithms that are trained online. Examples include model selection in streaming environments, switching between trading strategies in finance, and orchestrating multiple contextual bandit or reinforcement learning agents. At each round, a learner must select one predictor among $K$ adaptive experts to make a prediction, while being able to update at most $M \le K$ of them under a fixed training budget.
  We address this problem in the \emph{stochastic setting} and introduce \algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that provides \emph{anytime regret guarantees}. Its confidence intervals are built directly from realized losses, require no additional optimization, and seamlessly reflect the convergence properties of the underlying experts. If each expert achieves internal regret $\tilde O(T^α)$, then \algname{M-LCB} ensures overall regret bounded by $\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} \;+\; (K/M)^{1-α}\,T^α\Bigr)$.
  To our knowledge, this is the first result establishing regret guarantees when multiple adaptive experts are trained simultaneously under per-round budget constraints. We illustrate the framework with two representative cases: (i) parametric models trained online with stochastic losses, and (ii) experts that are themselves multi-armed bandit algorithms. These examples highlight how \algname{M-LCB} extends the classical bandit paradigm to the more realistic scenario of coordinating stateful, self-learning experts under limited resources.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于带预算约束的专家学习的UCB型算法</div>
<div class="mono" style="margin-top:8px">在许多现代应用中，系统必须在多个在线训练的自适应学习算法之间动态选择。例如，包括流式环境中的模型选择、金融中交易策略的切换，以及协调多个上下文带入或强化学习代理。在每一轮中，学习者必须从 $K$ 个自适应专家中选择一个预测器进行预测，同时在固定的训练预算下，最多只能更新其中 $M \le K$ 个专家。
我们在此问题中考虑随机设置，并引入了 \algname{M-LCB}，这是一种计算高效的UCB型元算法，提供了 \emph{任意时间遗憾保证}。其置信区间直接基于实际损失构建，不需要额外的优化，并能无缝反映底层专家的收敛性质。如果每个专家实现内部遗憾 $\tilde O(T^α)$，则 \algname{M-LCB} 确保总体遗憾被限制在 $\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} \;+\; (K/M)^{1-α}\,T^α\Bigr)$。
据我们所知，这是首个在每轮预算限制下同时训练多个自适应专家时建立遗憾保证的结果。我们通过两个代表性案例来说明该框架：(i) 在随机损失下在线训练的参数模型，(ii) 专家本身是多臂老虎机算法。这些例子展示了 \algname{M-LCB} 如何将经典的带入范式扩展到更现实的场景，即在有限资源下协调具有状态的、自我学习的专家。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260119_0349.html">20260119_0349</a>
<a href="archive/20260118_0350.html">20260118_0350</a>
<a href="archive/20260117_0356.html">20260117_0356</a>
<a href="archive/20260116_0403.html">20260116_0403</a>
<a href="archive/20260115_0356.html">20260115_0356</a>
<a href="archive/20260114_0402.html">20260114_0402</a>
<a href="archive/20260113_0342.html">20260113_0342</a>
<a href="archive/20260112_0355.html">20260112_0355</a>
<a href="archive/20260111_0354.html">20260111_0354</a>
<a href="archive/20260110_0400.html">20260110_0400</a>
<a href="archive/20260109_0356.html">20260109_0356</a>
<a href="archive/20260108_0356.html">20260108_0356</a>
<a href="archive/20260107_0355.html">20260107_0355</a>
<a href="archive/20260106_0358.html">20260106_0358</a>
<a href="archive/20260105_0351.html">20260105_0351</a>
<a href="archive/20260104_0353.html">20260104_0353</a>
<a href="archive/20260103_0351.html">20260103_0351</a>
<a href="archive/20260102_0354.html">20260102_0354</a>
<a href="archive/20260101_0352.html">20260101_0352</a>
<a href="archive/20251231_0356.html">20251231_0356</a>
<a href="archive/20251230_0356.html">20251230_0356</a>
<a href="archive/20251229_0355.html">20251229_0355</a>
<a href="archive/20251228_0354.html">20251228_0354</a>
<a href="archive/20251227_0355.html">20251227_0355</a>
<a href="archive/20251226_0355.html">20251226_0355</a>
<a href="archive/20251225_0355.html">20251225_0355</a>
<a href="archive/20251224_0355.html">20251224_0355</a>
<a href="archive/20251223_0354.html">20251223_0354</a>
<a href="archive/20251222_0354.html">20251222_0354</a>
<a href="archive/20251221_0354.html">20251221_0354</a>
<a href="archive/20251220_0356.html">20251220_0356</a>
<a href="archive/20251219_0354.html">20251219_0354</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0346.html">20251217_0346</a>
<a href="archive/20251216_0347.html">20251216_0347</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
